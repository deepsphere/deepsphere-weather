{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import Dropdown, Layout, Output\n",
    "from IPython.display import set_matplotlib_formats, display\n",
    "# set_matplotlib_formats('svg')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12.0, 6.0]\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 'large'\n",
    "plt.rcParams['figure.titlesize'] = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.full_pipeline import load_data_split, WeatherBenchDatasetXarrayHealpixTemp, create_iterative_predictions_healpix_temp, compute_errors\n",
    "from modules.architectures import UNetSpherical\n",
    "from modules.test import compute_rmse, compute_weighted_rmse\n",
    "from modules.plotting import plot_rmses, plot_general_skills, plot_benchmark, plot_skillmaps, plot_benchmark_simple\n",
    "from modules.data import pix2ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(file_path):\n",
    "    global cfg\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            cfg = json.load(f)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def onSeletion(change):\n",
    "    file_path = change['new']\n",
    "    with output:\n",
    "        if openJson(file_path):\n",
    "            print(f'{datetime.now()} - {file_path} loaded')\n",
    "        else:\n",
    "            print(f'{datetime.now()} - Load {file_path} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files = glob.glob('configs/*.json')\n",
    "layout = Layout(width='35%', height='35px')\n",
    "output = Output()\n",
    "selection = Dropdown(options=config_files, description='Available configurations:', value=config_files[0] ,disabled=False, layout=layout, style={'description_width': 'initial'})\n",
    "print('=' * 50, 'Please select a configuration file below', '=' * 50)\n",
    "display(selection, output)\n",
    "selection.observe(onSeletion, names='value')\n",
    "onSeletion({'new': config_files[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params = {}\n",
    "net_params[\"sampling\"] = cfg['model_parameters'].get(\"sampling\", None)\n",
    "net_params[\"knn\"] = cfg['model_parameters'].get(\"knn\", None)\n",
    "net_params[\"conv_type\"] = cfg['model_parameters'].get(\"conv_type\", None)\n",
    "net_params[\"pool_method\"] = cfg['model_parameters'].get(\"pool_method\", None)\n",
    "net_params[\"ratio\"] = cfg['model_parameters'].get(\"ratio\", None)\n",
    "net_params[\"periodic\"] = cfg['model_parameters'].get(\"periodic\", None)\n",
    "\n",
    "if net_params[\"sampling\"] == 'healpix':\n",
    "    description = \"{}_{}_{}_{}_{}_{}\".format(*net_params.values())\n",
    "else:\n",
    "    net_params.pop('knn')\n",
    "    description = \"{}_{}_{}_{}_{}\".format(*net_params.values())\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = cfg['directories']['datadir']\n",
    "input_dir = datadir + cfg['directories']['input_dir']\n",
    "result_path = cfg['directories']['save_dir']\n",
    "model_path = result_path + cfg['directories']['model_save_path']\n",
    "prediction_path = result_path + cfg['directories']['pred_save_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = cfg['training_constants']['chunk_size']\n",
    "train_years = cfg['training_constants']['train_years']\n",
    "val_years = cfg['training_constants']['val_years']\n",
    "test_years = cfg['training_constants']['test_years']\n",
    "nodes = cfg['training_constants']['nodes']\n",
    "max_lead_time = cfg['training_constants']['max_lead_time']\n",
    "nb_timesteps = cfg['training_constants']['nb_timesteps']\n",
    "len_sqce = cfg['model_parameters']['len_sqce']\n",
    "delta_t = cfg['model_parameters']['delta_t']\n",
    "in_features = cfg['model_parameters']['in_features']\n",
    "out_features = cfg['model_parameters']['out_features']\n",
    "resolution = cfg[\"model_parameters\"][\"resolution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = result_path + 'metrics/'\n",
    "figures_path = result_path + 'figures/'\n",
    "os.makedirs(metrics_path, exist_ok=True)\n",
    "os.makedirs(figures_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_mfdataset(prediction_path + 'observations.nc', combine='by_coords', chunks={'time':chunk_size})\n",
    "rmses_weyn = xr.open_dataset(datadir + 'metrics/rmses_weyn.nc')\n",
    "\n",
    "constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg_standardized.nc')\n",
    "orog = constants['orog']\n",
    "lsm = constants['lsm']\n",
    "lats = constants['lat2d']\n",
    "slt = constants['slt']\n",
    "num_constants = len([orog, lats, lsm, slt])\n",
    "\n",
    "train_mean_ = xr.open_mfdataset(f'{input_dir}mean_train_features_dynamic.nc')\n",
    "train_std_ = xr.open_mfdataset(f'{input_dir}std_train_features_dynamic.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, ds_test = load_data_split(input_dir, train_years, val_years, test_years, chunk_size)\n",
    "\n",
    "# Testing data\n",
    "testing_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_test, out_features=out_features,\n",
    "                                                  len_sqce=len_sqce, delta_t=delta_t, years=test_years, \n",
    "                                                  nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                  mean=train_mean_, std=train_std_, \n",
    "                                                  max_lead_time=max_lead_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_tensor = torch.tensor(xr.merge([orog, lats, lsm, slt], compat='override').to_array().values, dtype=torch.float)\n",
    "# standardize \n",
    "constants_tensor_mean = torch.mean(constants_tensor, dim=1, keepdim=True)\n",
    "constants_tensor_std = torch.std(constants_tensor, dim=1, keepdim=True)\n",
    "constants_tensor = (constants_tensor - constants_tensor_mean) / (constants_tensor_std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetSpherical(N=nodes, in_channels=in_features * len_sqce, out_channels=out_features, kernel_size=3, **net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onSelectAndLoad(change):\n",
    "    file_path = change['new']\n",
    "    with output_state:\n",
    "        try:\n",
    "            global model\n",
    "            model.load_state_dict(torch.load(file_path), strict=False)\n",
    "            print(f'{datetime.now()} - {file_path} loaded')\n",
    "        except:\n",
    "            print(f'{datetime.now()} - Load {file_path} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_epoch = lambda x: int(x.split('_')[-1][:-3]) # filename e.g. XXXX_epoch_1.h5\n",
    "saved_models = glob.glob(model_path + '*.h5')\n",
    "saved_models.sort(key=extract_epoch, reverse=True)\n",
    "\n",
    "layout_state = Layout(width='50%', height='35px')\n",
    "output_state = Output()\n",
    "select_state = Dropdown(options=saved_models, description='Saved state dictionaries:', value=saved_models[0] ,disabled=False, layout=layout_state, style={'description_width': 'initial'})\n",
    "print('=' * 50, 'Please select a state dict below', '=' * 50)\n",
    "display(select_state, output_state)\n",
    "select_state.observe(onSelectAndLoad, names='value')\n",
    "onSelectAndLoad({'new': saved_models[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda: 0'\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_name(path, tag, desc, epoch):\n",
    "    return \"{}{}_{}_epoch_{}.nc\".format(path, tag, desc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = extract_epoch(select_state.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_filename = generate_file_name(prediction_path, 'pred', description, epoch)\n",
    "rmse_filename = generate_file_name(metrics_path, 'rmse', description, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    pred, lead_times, times = create_iterative_predictions_healpix_temp(model, device, testing_ds, constants_tensor.transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = []\n",
    "for ind, var in enumerate(['z', 't']):       \n",
    "    curr = xr.DataArray(pred[:, :, :, ind], dims=['lead_time', 'time', 'node'], coords={'lead_time': lead_times, 'time': times[:pred.shape[1]], 'node': np.arange(nodes)}, name=var)\n",
    "    das.append(curr)\n",
    "\n",
    "if net_params['sampling'] == 'equiangular':\n",
    "    out_lat, out_lon = pix2ang(nodes)\n",
    "elif net_params['sampling'] == 'healpix':\n",
    "    nside = int(np.sqrt(nodes/12))\n",
    "    out_lat, out_lon = hp.pix2ang(nside, np.arange(nodes), lonlat=True)\n",
    "    \n",
    "pred_merged = xr.merge(das)\n",
    "pred_merged = pred_merged.assign_coords({'lat': out_lat, 'lon': out_lon})\n",
    "\n",
    "pred_merged.to_netcdf(pred_filename)\n",
    "\n",
    "# select observations\n",
    "obs_curr = obs.isel(time=slice(6, pred_merged.time.shape[0] + 6))\n",
    "\n",
    "# compute RMSE\n",
    "if net_params['sampling'] == 'equiangular':\n",
    "    rmse = compute_weighted_rmse(pred_merged, obs_curr)\n",
    "elif net_params['sampling'] == 'healpix':\n",
    "    rmse = compute_rmse(pred_merged, obs_curr)\n",
    "rmse.to_netcdf(rmse_filename)\n",
    "    \n",
    "    \n",
    "# plot RMSE\n",
    "print('Z500 - 0:', rmse.z.values[0])\n",
    "print('T850 - 0:', rmse.t.values[0])\n",
    "\n",
    "plot_rmses(rmse, rmses_weyn.rename({'z500':'z', 't850':'t'}).isel(lead_time=list(range(20))), lead_time=6)\n",
    "\n",
    "#del spherical_unet\n",
    "#del prediction_ds, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "corr_map, rbias_map, rsd_map, rmse_map, obs_rmse, rmse_map_norm = compute_errors(pred_merged, obs_curr)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_spherical = xr.load_dataset(rmse_filename)\n",
    "rbias_spherical = rbias_map.mean('node').compute()\n",
    "rsd_spherical = rsd_map.mean('node').compute()\n",
    "corr_spherical = corr_map.mean('node').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbias_spherical.to_netcdf(generate_file_name(metrics_path, 'rbias', description, epoch))\n",
    "rsd_spherical.to_netcdf(generate_file_name(metrics_path, 'rsd', description, epoch))\n",
    "corr_spherical.to_netcdf(generate_file_name(metrics_path, 'corr', description, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_simple(rmse_spherical, description, lead_times, input_dir=datadir, output_dir=figures_path, title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_general_skills(rmse_map_norm, corr_map, rbias_map, rsd_map, description, lead_times, output_dir=figures_path, title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skillmaps(rmse_map_norm, rsd_map, rbias_map, corr_map, description, lead_times, resolution, output_dir=figures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weather]",
   "language": "python",
   "name": "conda-env-weather-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
