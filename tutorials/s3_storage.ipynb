{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and storing data on (EPFL) S3\n",
    "\n",
    "* As a filesystem with S3Fs and fsspec.\n",
    "* As a storage for n-d arrays with zarr and xarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3Fs\n",
    "\n",
    "* Pythonic filesystem interface to S3\n",
    "* <https://s3fs.readthedocs.io/en/latest/index.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    key='L6VMMUCY3DCGQJB5AFWS',\n",
    "    secret='+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "    client_kwargs={\n",
    "       'endpoint_url': 'https://s3.epfl.ch'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(fs.ls('10380-c19e273816a6aca044c096f3a6d4d322'))\n",
    "with fs.open('10380-c19e273816a6aca044c096f3a6d4d322/hello.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With credentials passed to botocore directly.\n",
    "fs = s3fs.S3FileSystem(client_kwargs={  \n",
    "    'endpoint_url': 'https://s3.epfl.ch',\n",
    "    'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "    'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "})\n",
    "\n",
    "print(fs.ls('10380-c19e273816a6aca044c096f3a6d4d322'))\n",
    "with fs.open('10380-c19e273816a6aca044c096f3a6d4d322/hello.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botocore will read the following environment variables to get credentials.\n",
    "# That's better than storing them in code.\n",
    "#os.environ['AWS_ACCESS_KEY_ID']\n",
    "#os.environ['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fsspec\n",
    "\n",
    "* generic remote filesystem interface (uses and used by s3fs)\n",
    "* <https://filesystem-spec.readthedocs.io/en/latest/usage.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\n",
    "    's3',\n",
    "    client_kwargs={\n",
    "       'endpoint_url': 'https://s3.epfl.ch',\n",
    "       'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "       'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "    }\n",
    ")\n",
    "\n",
    "print(fs.ls('10380-c19e273816a6aca044c096f3a6d4d322'))\n",
    "with fs.open('10380-c19e273816a6aca044c096f3a6d4d322/hello.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = fsspec.open(\n",
    "    's3://10380-c19e273816a6aca044c096f3a6d4d322/hello.txt',\n",
    "    client_kwargs={\n",
    "       'endpoint_url': 'https://s3.epfl.ch',\n",
    "       'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "       'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "    }\n",
    ")\n",
    "\n",
    "with of as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zarr\n",
    "\n",
    "* data format that is more distributed / cloud friendly than netCDF/HDF5 because chunks are separate files\n",
    "* can be saved to filesystem (disk) or object store (cloud, database)\n",
    "* <https://zarr.readthedocs.io/en/stable/tutorial.html#distributed-cloud-storage>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import s3fs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the S3 store with S3Fs.\n",
    "fs = s3fs.S3FileSystem(client_kwargs={  \n",
    "    'endpoint_url': 'https://s3.epfl.ch',\n",
    "    'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "    'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "})\n",
    "store = s3fs.S3Map('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr', fs)\n",
    "\n",
    "# Optional cache.\n",
    "#store = zarr.LRUStoreCache(store, max_size=2**28)\n",
    "\n",
    "# Open the root group.\n",
    "root = zarr.group(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and read attributes.\n",
    "root.attrs['readme'] = 'Demo zarr store on EPFL S3'\n",
    "print(list(root.attrs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some data.\n",
    "a = np.arange(10e7, dtype='i4').reshape((10000, 10000))\n",
    "z = zarr.array(a, chunks=(1000, 1000))\n",
    "print(z.info)\n",
    "\n",
    "# Store it.\n",
    "root['foo/bar'] = z\n",
    "\n",
    "# A zarr array is a directory of chunks (with a JSON metadata file).\n",
    "print('{} files\\n'.format(len(fs.ls('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr/foo/bar'))))\n",
    "\n",
    "# Some info about our hierarchy of groups.\n",
    "print(root.info)\n",
    "print(root.tree())\n",
    "\n",
    "# Access the data back.\n",
    "z = root['foo/bar']\n",
    "z.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the group with fsspec.\n",
    "g = zarr.open_group(\n",
    "    's3://10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr',\n",
    "    storage_options={'client_kwargs': {\n",
    "       'endpoint_url': 'https://s3.epfl.ch',\n",
    "       'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "       'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "    }}\n",
    ")\n",
    "g['foo/bar'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the group with fsspec and a cache.\n",
    "g = zarr.open_group(\n",
    "    'simplecache::s3://10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr',\n",
    "    storage_options={'s3': {'client_kwargs': {\n",
    "       'endpoint_url': 'https://s3.epfl.ch',\n",
    "       'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "       'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "    }}}\n",
    ")\n",
    "g['foo/bar'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsequent access is faster if opened with cache.\n",
    "g['foo/bar'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete store.\n",
    "fs.rm('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray\n",
    "\n",
    "* n-dimensional labeled array\n",
    "* supports multiple storage backends, including zarr (but also netCDF or GRIB)\n",
    "* <https://xarray.pydata.org/en/stable/io.html#zarr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the S3 store with S3Fs.\n",
    "fs = s3fs.S3FileSystem(client_kwargs={  \n",
    "    'endpoint_url': 'https://s3.epfl.ch',\n",
    "    'aws_access_key_id': 'L6VMMUCY3DCGQJB5AFWS',\n",
    "    'aws_secret_access_key': '+zM+rME107dXsyJf1Dxa8BBePMLF1ZbmAz+GJ91h',\n",
    "})\n",
    "store = s3fs.S3Map('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr', fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    {\"foo\": ((\"x\", \"y\"), np.random.rand(4, 5))},\n",
    "    coords={\n",
    "        \"x\": [10, 20, 30, 40],\n",
    "        \"y\": pd.date_range(\"2000-01-01\", periods=5),\n",
    "        \"z\": (\"x\", list(\"abcd\")),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_zarr(store, mode='w', consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.open_zarr(store, consolidated=True)\n",
    "ds2['foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fs.ls('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr'))  # doesn't show directories\n",
    "fs.rm('10380-c19e273816a6aca044c096f3a6d4d322/demo.zarr', recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr-python3",
   "language": "python",
   "name": "zarr-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
