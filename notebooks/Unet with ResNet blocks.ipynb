{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Residual Blocks on Unet architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "import pygsp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import BatchNorm1d, BatchNorm2d, Conv1d\n",
    "\n",
    "from deepsphere.utils.samplings import equiangular_dimension_unpack\n",
    "\n",
    "from modules.layers import (ConvCheb, PoolMaxHealpix, UnpoolMaxHealpix,\n",
    "                            ConvChebTemp, PoolMaxTempHealpix, UnpoolMaxTempHealpix)\n",
    "\n",
    "from modules.healpix_models import _compute_laplacian_healpix, ConvBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dAuto(Conv1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2) # dynamic add padding based on the kernel_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetSphericalHealpixResidual(torch.nn.Module):\n",
    "    \"\"\"Spherical GCNN UNet\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes in the input graph\n",
    "    in_channels : int\n",
    "        Number of channels in the input graph.\n",
    "    out_channels : int\n",
    "        Number of channels in the output graph.\n",
    "    kernel_size : int\n",
    "        Chebychev polynomial degree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, in_channels, out_channels, kernel_size):        \n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "       \n",
    "        laplacians = []\n",
    "        for i, nodes in enumerate([3072, 768, 192]):\n",
    "            laplacian = _compute_laplacian_healpix(nodes)\n",
    "            laplacians.append(laplacian)\n",
    "        \n",
    "        \n",
    "        # Pooling - unpooling\n",
    "        self.pooling = PoolMaxHealpix(kernel_size=4)\n",
    "        self.unpool = UnpoolMaxHealpix(kernel_size=4)\n",
    "        \n",
    "        # Encoding block 1\n",
    "        self.conv11 = ConvBlock(in_channels, max(in_channels, 16), kernel_size, laplacians[0])\n",
    "        self.conv12 = ConvBlock(max(in_channels, 16), max(in_channels, 32), kernel_size, laplacians[0])\n",
    "        self.conv13 = ConvBlock(max(in_channels, 32), 64, kernel_size, laplacians[0])\n",
    "        \n",
    "        self.conv1_res = Conv1dAuto(in_channels, 64, 1)\n",
    "        \n",
    "        # Encoding block 2\n",
    "        self.conv21 = ConvBlock(64, 88, kernel_size, laplacians[1])\n",
    "        self.conv22 = ConvBlock(88, 110, kernel_size, laplacians[1])\n",
    "        self.conv23 = ConvBlock(110, 128, kernel_size, laplacians[1])\n",
    "        \n",
    "        self.conv2_res = Conv1dAuto(64, 128, 1)\n",
    "       \n",
    "        # Encoding block 3\n",
    "        self.conv31 = ConvBlock(128, 256, kernel_size, laplacians[2])\n",
    "        self.conv32 = ConvBlock(256, 256, kernel_size, laplacians[2])\n",
    "        self.conv33 = ConvBlock(256, 128, kernel_size, laplacians[2])\n",
    "        \n",
    "        self.conv3_res = Conv1dAuto(128, 128, 1)\n",
    "        \n",
    "        # Decoding block 4\n",
    "        self.uconv21 = ConvBlock(256, 128, kernel_size, laplacians[1])\n",
    "        self.uconv22 = ConvBlock(128, 64, kernel_size, laplacians[1])\n",
    "        \n",
    "        # Decoding block 4\n",
    "        self.uconv11 = ConvBlock(128, 64, kernel_size, laplacians[0])\n",
    "        self.uconv12 = ConvBlock(64, 32, kernel_size, laplacians[0])\n",
    "        self.uconv13 = ConvCheb(32, out_channels, kernel_size, laplacians[0])\n",
    "        \n",
    "         \n",
    "    def encode(self, x):\n",
    "        \"\"\" Encodes an input into a lower dimensional space applying convolutional, batch normalisation and pooling layers\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor of shape batch_size x n_vertices x in_channels\n",
    "            Input data\n",
    "        Returns\n",
    "        -------\n",
    "       x_enc3, x_enc2, x_enc1, idx2, idx1 : torch.Tensors of shapes batch_size x n_vertices x layer_channels + list(int)\n",
    "            Encoded data at the different encoding stages and the indices indicating the locations of the maxium values in\n",
    "            unpooled images.\n",
    "        \"\"\"\n",
    "        #x_enc1 = self.dropout1(x_enc1)\n",
    "        \n",
    "        # Block 1\n",
    "        \n",
    "        x_enc1 = self.conv11(x)\n",
    "        x_enc1 = self.conv12(x_enc1)\n",
    "        x_enc1 = self.conv13(x_enc1)\n",
    "        #print(x_enc1.shape)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x_enc1 += torch.transpose(self.conv1_res(torch.transpose(x, 2,1)), 2,1)\n",
    "        #x_enc1 += self.conv1_res(x.transpose(0,2,1)).transpose(0,2,1)\n",
    "        \n",
    "        # Block 2\n",
    "        x_enc2_ini, idx1 = self.pooling(x_enc1)\n",
    "        x_enc2 = self.conv21(x_enc2_ini)\n",
    "        x_enc2 = self.conv22(x_enc2)\n",
    "        x_enc2 = self.conv23(x_enc2)\n",
    "        x_enc2 += torch.transpose(self.conv2_res(torch.transpose(x_enc2_ini, 2,1)),2,1)\n",
    "        #x_enc2 += self.conv2_res(x_enc1.transpose(0,2,1)).transpose(0,2,1)\n",
    "        \n",
    "        # Block 3\n",
    "        x_enc3_ini, idx2 = self.pooling(x_enc2)\n",
    "        x_enc3 = self.conv31(x_enc3_ini)\n",
    "        x_enc3 = self.conv32(x_enc3)\n",
    "        x_enc3 = self.conv33(x_enc3)\n",
    "        x_enc3 += torch.transpose(self.conv3_res(torch.transpose(x_enc3_ini, 2,1)),2,1)\n",
    "        #x_enc3 += self.conv3_res(x_enc2.transpose(0,2,1)).transpose(0,2,1)\n",
    "        \n",
    "        return x_enc3, x_enc2, x_enc1, idx2, idx1\n",
    "    \n",
    "    def decode(self, x_enc3, x_enc2, x_enc1, idx2, idx1):\n",
    "        \"\"\" Decodes low dimensional data into high dimensional applying convolutional, batch normalisation, \n",
    "        unpooling layers and skip connections\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_enc3, x_enc2, x_enc1, idx2, idx1 : torch.Tensors of shapes batch_size x n_vertices x layer_channels + list(int)\n",
    "            Encoded data at the different encoding stages and the indices indicating the locations of the maxium values in\n",
    "            unpooled images.\n",
    "        Returns\n",
    "        -------\n",
    "        x : torch.Tensor of shape batch_size x n_vertices x out_channels\n",
    "            Decoded data\n",
    "        \"\"\"\n",
    "\n",
    "        # Block 2\n",
    "        x = self.unpool(x_enc3, idx2)\n",
    "        x = torch.cat((x, x_enc2), dim=2)\n",
    "        x = self.uconv21(x)\n",
    "        x = self.uconv22(x)\n",
    "        \n",
    "        # Block 1\n",
    "        x = self.unpool(x, idx1)\n",
    "        x = torch.cat((x, x_enc1), dim=2)\n",
    "        x = self.uconv11(x)\n",
    "        x = self.uconv12(x)\n",
    "        x = self.uconv13(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        This function overrides the state dict in order to be able to save the model.\n",
    "        This can be removed as soon as saving sparse matrices has been added to Pytorch.\n",
    "        \"\"\"\n",
    "        state_dict = super().state_dict(*args, **kwargs)\n",
    "        del_keys = []\n",
    "        for key in state_dict:\n",
    "            if \"laplacian\" in key:\n",
    "                del_keys.append(key)\n",
    "        for key in del_keys:\n",
    "            del state_dict[key]\n",
    "        return state_dict\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor of shape batch_size x n_vertices x in_channels\n",
    "            Input data\n",
    "        Returns\n",
    "        -------\n",
    "        x : torch.Tensor of shape batch_size x n_vertices x out_channels\n",
    "            Model output\n",
    "        \"\"\"\n",
    "        x_encoded = self.encode(x)\n",
    "        output = self.decode(*x_encoded)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import healpy as hp\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.utils import train_model_2steps_temp, init_device\n",
    "from modules.data import WeatherBenchDatasetXarrayHealpixTemp\n",
    "from modules.healpix_models import UNetSphericalHealpix, UNetSphericalTempHealpix\n",
    "from modules.test import create_iterative_predictions_healpix_temp, compute_rmse_healpix\n",
    "from modules.plotting import plot_rmses\n",
    "\n",
    "datadir = \"../data/healpix/\"\n",
    "input_dir = datadir + \"5.625deg_nearest/\"\n",
    "model_save_path = datadir + \"models/\"\n",
    "pred_save_path = datadir + \"predictions/\"\n",
    "\n",
    "if not os.path.isdir(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "if not os.path.isdir(pred_save_path):\n",
    "    os.mkdir(pred_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521\n",
    "\n",
    "train_years = ('1979', '2012')#('1979', '2012')\n",
    "val_years = ('2013', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "nodes = 12*16*16\n",
    "max_lead_time = 5*24\n",
    "nb_timesteps = 2\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "gpu = [0]\n",
    "num_workers = 10\n",
    "pin_memory = True\n",
    "\n",
    "nb_epochs = 20\n",
    "learning_rate = 8e-3\n",
    "\n",
    "obs = xr.open_mfdataset(pred_save_path + 'observations_nearest.nc', combine='by_coords', chunks={'time':chunk_size})\n",
    "rmses_weyn = xr.open_dataset(datadir + 'metrics/rmses_weyn.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import WeatherBenchDatasetIterative\n",
    "class WeatherBenchDatasetXarrayHealpixTemp(Dataset):\n",
    "    \n",
    "    \"\"\" Dataset used for graph models (1D), where data is loaded from stored numpy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray Dataset\n",
    "        Dataset containing the input data\n",
    "    out_features : int\n",
    "        Number of output features\n",
    "    delta_t : int\n",
    "        Temporal spacing between samples in temporal sequence (in hours)\n",
    "    len_sqce : int\n",
    "        Length of the input and output (predicted) sequences\n",
    "    years : tuple(str)\n",
    "        Years used to split the data\n",
    "    nodes : float\n",
    "        Number of nodes each sample has\n",
    "    max_lead_time : int\n",
    "        Maximum lead time (in case of iterative predictions) in hours\n",
    "    load : bool\n",
    "        If true, load dataset to RAM\n",
    "    mean : np.ndarray of shape 2\n",
    "        Mean to use for data normalization. If None, mean is computed from data\n",
    "    std : np.ndarray of shape 2\n",
    "        std to use for data normalization. If None, mean is computed from data\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, ds, out_features, delta_t, len_sqce, years, nodes, nb_timesteps, \n",
    "                 max_lead_time=None, load=True, mean=None, std=None):\n",
    "        \n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        self.len_sqce = len_sqce\n",
    "        self.years = years\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.out_features = out_features\n",
    "        self.max_lead_time = max_lead_time\n",
    "        self.nb_timesteps = nb_timesteps\n",
    "        \n",
    "        self.data = ds.to_array(dim='level', name='Dataset').transpose('time', 'node', 'level')\n",
    "        self.in_features = self.data.shape[-1]\n",
    "        \n",
    "        self.mean = self.data.mean(('time', 'node')).compute() if mean is None else mean\n",
    "        self.std = self.data.std(('time', 'node')).compute() if std is None else std\n",
    "        \n",
    "        eps = 0.001 #add to std to avoid division by 0\n",
    "        \n",
    "        # Count total number of samples\n",
    "        total_samples = self.data.shape[0]        \n",
    "        \n",
    "        if max_lead_time is None:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t\n",
    "        else:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t - max_lead_time\n",
    "        \n",
    "        # Normalize\n",
    "        self.data = (self.data - self.mean.to_array(dim='level')) / (self.std.to_array(dim='level') + eps)\n",
    "        self.data.persist()\n",
    "        \n",
    "        self.idxs = np.array(range(self.n_samples))\n",
    "        \n",
    "        print('Loading data to RAM...')\n",
    "        t = time.time()\n",
    "        self.data.load()\n",
    "        print('Time: {:.2f}s'.format(time.time() - t))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, len_sqce, n_features]\n",
    "            \n",
    "        \"\"\"\n",
    "        idx_data = idx#self.idxs[idx]\n",
    "        #1,0,2\n",
    "        \n",
    "        #batch[0] --> (batch_size, num_nodes, n_features*len_sq)\n",
    "        idx_full = np.concatenate(np.array([[idx_data+self.delta_t*k] for k in range(self.len_sqce+2)]).reshape(-1,1)) # ex: len_sqce=2 --> we need 0,1,2,3\n",
    "        #idx_full = np.concatenate([idx_data+delta_t,  idx_data + delta_t * len_sqce, idx_data + delta_t * (len_sqce+1)])\n",
    "        dat = self.data.isel(time=idx_full).values\n",
    "        \n",
    "        \n",
    "        X = (\n",
    "            torch.tensor(dat[:len(idx)*self.len_sqce,:,:] , \\\n",
    "                         dtype=torch.float).reshape(len(idx)*self.len_sqce, self.nodes, -1),\n",
    "        )\n",
    "        \n",
    "        y = (torch.tensor(dat[len(idx):len(idx)*(self.len_sqce+1),:,:],\\\n",
    "                         dtype=torch.float).reshape(len(idx)*self.len_sqce, self.nodes, -1),\\\n",
    "             torch.tensor(dat[len(idx)*(self.len_sqce):,:,:out_features],\\\n",
    "                         dtype=torch.float).reshape(len(idx)*self.len_sqce, self.nodes, -1)\n",
    "        \n",
    "        )\n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'z':'z500'})\n",
    "t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'t':'t850'})\n",
    "rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords', chunks={'time':chunk_size})\n",
    "\n",
    "z500 = z500.isel(time=slice(7, None))\n",
    "t850 = t850.isel(time=slice(7, None))\n",
    "\n",
    "constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg_standardized.nc')\n",
    "\n",
    "orog = constants['orog']\n",
    "lsm = constants['lsm']\n",
    "lats = constants['lat2d']\n",
    "slt = constants['slt']\n",
    "cos_lon = constants['cos_lon']\n",
    "sin_lon = constants['sin_lon']\n",
    "\n",
    "num_constants = len([orog, lats, lsm, slt])\n",
    "constants_tensor = torch.tensor(xr.merge([orog, lats, lsm, slt], compat='override').to_array().values, \\\n",
    "                            dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([z500, t850, rad], compat='override')\n",
    "#ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "\n",
    "ds_train = ds.sel(time=slice(*train_years))\n",
    "ds_valid = ds.sel(time=slice(*val_years))\n",
    "ds_test = ds.sel(time=slice(*test_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_tensor = (constants_tensor - torch.mean(constants_tensor, dim=1).view(-1,1).expand(4, 3072)) / torch.std(constants_tensor, dim=1).view(-1,1).expand(4, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_ = xr.open_mfdataset(f'{input_dir}mean_train_features_dynamic.nc')\n",
    "train_std_ = xr.open_mfdataset(f'{input_dir}std_train_features_dynamic.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sqce = 2\n",
    "# define time resolution\n",
    "delta_t = 6\n",
    "\n",
    "# predict 5days data\n",
    "max_lead_time = 5*24\n",
    "in_features = 7\n",
    "out_features = 2\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"all_const_len2_delta6_resblock\"\n",
    "\n",
    "model_filename = model_save_path + \"spherical_unet_\" + description + \".h5\"\n",
    "pred_filename = pred_save_path + \"spherical_unet_\" + description + \".nc\"\n",
    "rmse_filename = datadir + 'metrics/rmse_' + description + '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to RAM...\n",
      "Time: 43.87s\n",
      "Loading data to RAM...\n",
      "Time: 4.28s\n"
     ]
    }
   ],
   "source": [
    "# Train and validation data\n",
    "training_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_train, out_features=out_features, delta_t=delta_t,\n",
    "                                                   len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                   years=train_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                   mean=train_mean_, std=train_std_, load=False)\n",
    "validation_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_valid, out_features=out_features, delta_t=delta_t,\n",
    "                                                     len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                     years=val_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                     mean=train_mean_, std=train_std_, load=False)\n",
    "\n",
    "dl_train = DataLoader(training_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers,\\\n",
    "                      pin_memory=pin_memory)\n",
    "\n",
    "dl_val = DataLoader(validation_ds, batch_size=batch_size*2, shuffle=False, num_workers=num_workers,\\\n",
    "                    pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2steps(model, device, training_ds, constants, batch_size, epochs, lr, validation_ds):    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    n_samples = training_ds.n_samples\n",
    "    n_samples_val = validation_ds.n_samples\n",
    "    num_nodes = training_ds.nodes\n",
    "    num_constants = constants.shape[1]\n",
    "    out_features = training_ds.out_features\n",
    "    \n",
    "    constants_expanded = constants.expand(batch_size, num_nodes, num_constants)\n",
    "    constants1 = constants_expanded.to(device)\n",
    "    idxs_val = validation_ds.idxs\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('\\rEpoch : {}'.format(epoch), end=\"\")\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()  \n",
    "        \n",
    "        random.shuffle(training_ds.idxs)\n",
    "        idxs = training_ds.idxs\n",
    "        \n",
    "        batch_idx = 0\n",
    "        \n",
    "        for i in range(0, n_samples - batch_size, batch_size):\n",
    "            i_next = min(i + batch_size, n_samples)\n",
    "            \n",
    "            if len(idxs[i:i_next]) < batch_size:\n",
    "                constants_expanded = contants.expand(len(idxs[i:i_next]), num_nodes, num_constants)\n",
    "                constants1 = constants_expanded.to(device)\n",
    "        \n",
    "            \n",
    "            #t1 = time.time()\n",
    "            batch, labels = training_ds[idxs[i:i_next]]\n",
    "            \n",
    "            #t2 = time.time()\n",
    "            \n",
    "            # Transfer to GPU\n",
    "            batch_size = batch[0].shape[0]//2\n",
    "            \n",
    "            batch1 = torch.cat((batch[0][:batch_size, :,:], \\\n",
    "                                constants_expanded,batch[0][batch_size:, :,:] ,constants_expanded), dim=2).to(device)\n",
    "            #batch1 = torch.cat((batch[0], constants_expanded), dim=2).to(device)\n",
    "            \n",
    "            label1 = labels[0].to(device)\n",
    "            label2 = labels[1].to(device)\n",
    "            \n",
    "            #t3 = time.time()\n",
    "            batch_size = batch1.shape[0]\n",
    "            \n",
    "            # Model\n",
    "            \n",
    "            #t4 = time.time()\n",
    "            output1 = model(batch1)  \n",
    "            #t5 = time.time()\n",
    "            # [z_tdelta1, t_tdelta1, toa_tdelta1, constants, z_tdelta2, t_tdelta2, toa_tdelta2, constants]\n",
    "            toa_delta = batch[0][batch_size:, :,-1].view(-1, num_nodes, 1).to(device)\n",
    "            batch2 = torch.cat((output1, toa_delta, constants1, \\\n",
    "                               label1[batch_size:, :,:], constants1), dim=2)\n",
    "            \n",
    "            #batch2 = torch.cat((output1, label1[:,:,-1].view(-1, num_nodes, 1), constants1), dim=2)\n",
    "            #t6 = time.time()\n",
    "            output2 = model(batch2)\n",
    "            #t7 = time.time()\n",
    "            loss = criterion(output1, label1[batch_size:,:,:out_features]) + criterion(output2, label2[batch_size:,:,:out_features])\n",
    "            #t8 = time.time()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * batch_size\n",
    "            \n",
    "            \n",
    "            #print('\\nTime to read batch: {}s'.format(t2-t1))\n",
    "            #print('Time to transfer data to GPU: {}s'.format(t3-t2))\n",
    "            #print('Time to process input 1: {}s'.format(t5-t4))\n",
    "            #print('Time to process input 2: {}s'.format(t7-t6))\n",
    "            #print('Time to compute loss: {}s'.format(t8-t7))\n",
    "            #print('\\n')\n",
    "            if batch_idx%50 == 0:\n",
    "                print('\\rBatch idx: {}; Loss: {:.3f}'.format(batch_idx, train_loss/(batch_size*(batch_idx+1))), end=\"\")\n",
    "            batch_idx += 1\n",
    "        \n",
    "        train_loss = train_loss / n_samples\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        constants1 = constants_expanded.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            index = 0\n",
    "            \n",
    "            for i in range(0, n_samples_val - batch_size, batch_size):\n",
    "                i_next = min(i + batch_size, n_samples_val)\n",
    "\n",
    "                if len(idxs_val[i:i_next]) < batch_size:\n",
    "                    constants_expanded = contants.expand(len(idxs_val[i:i_next]), num_nodes, num_constants)\n",
    "                    constants1 = constants_expanded.to(device)\n",
    "\n",
    "\n",
    "                #t1 = time.time()\n",
    "                batch, labels = validation_ds[idxs_val[i:i_next]]\n",
    "                # Transfer to GPU\n",
    "                batch_size = batch[0].shape[0]//2\n",
    "            \n",
    "                batch1 = torch.cat((batch[0][:batch_size, :,:], \\\n",
    "                                    constants_expanded,batch[0][batch_size:, :,:] ,constants_expanded), dim=2).to(device)\n",
    "                label1 = labels[0].to(device)\n",
    "                label2 = labels[1].to(device)\n",
    "\n",
    "                batch_size = batch1.shape[0]\n",
    "\n",
    "                output1 = model(batch1)  \n",
    "                toa_delta = batch[0][batch_size:, :,-1].view(-1, num_nodes, 1).to(device)\n",
    "                batch2 = torch.cat((output1, toa_delta, constants1, \\\n",
    "                                   label1[batch_size:, :,:], constants1), dim=2)\n",
    "                output2 = model(batch2)\n",
    "                \n",
    "                val_loss = val_loss + (criterion(output1, label1[batch_size:,:,:out_features]).item() \n",
    "                                       + criterion(output2, label2[batch_size:,:,:out_features]).item()) * batch_size\n",
    "                index = index + batch_size\n",
    "                \n",
    "        val_loss = val_loss / n_samples_val\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherical_unet = UNetSphericalHealpixResidual(N=nodes, in_channels=in_features*len_sqce, out_channels=out_features, kernel_size=3)\n",
    "spherical_unet, device = init_device(spherical_unet, gpu=gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch idx: 1300; Loss: 0.105"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train_model_2steps(spherical_unet, device, training_ds, constants_tensor.transpose(1,0), \\\n",
    "                                          batch_size=100, epochs=7, \\\n",
    "                                           lr=learning_rate, validation_ds=validation_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
