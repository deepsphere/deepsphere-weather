{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check influence of different parameters in performance. \n",
    "\n",
    "Check influence of:\n",
    "- specifying different chunk sizes and chunking along different dimensions\n",
    "- use already standardized data --> does it save memory?\n",
    "- use ``` .persist()``` to load data in a distributed way and speed up reading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import healpy as hp\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.utils import train_model_2steps, init_device\n",
    "from modules.data import WeatherBenchDatasetXarrayHealpix\n",
    "from modules.healpix_models import UNetSphericalHealpix\n",
    "from modules.test import create_iterative_predictions_healpix\n",
    "from modules.test import compute_rmse_healpix\n",
    "from modules.plotting import plot_rmses\n",
    "\n",
    "datadir = \"../data/healpix/\"\n",
    "input_dir = datadir + \"5.625deg_nearest/\"\n",
    "model_save_path = datadir + \"models/\"\n",
    "pred_save_path = datadir + \"predictions/\"\n",
    "\n",
    "train_years = ('1979', '2012')\n",
    "val_years = ('2013', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "nodes = 12*16*16\n",
    "max_lead_time = 5*24\n",
    "lead_time = 6\n",
    "out_features = 2\n",
    "nb_timesteps = 2\n",
    "len_sqce = 2\n",
    "#Â define time resolution\n",
    "delta_t = 6\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,4\"\n",
    "gpu = [0,1]\n",
    "num_workers = 10\n",
    "pin_memory = True\n",
    "batch_size = 95\n",
    "\n",
    "nb_epochs = 10\n",
    "learning_rate = 8e-3\n",
    "\n",
    "#obs = xr.open_mfdataset(pred_save_path + 'observations_nearest.nc', combine='by_coords', chunks={'time':483})\n",
    "#rmses_weyn = xr.open_dataset(datadir + 'metrics/rmses_weyn.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import WeatherBenchDatasetIterative\n",
    "class WeatherBenchDatasetXarrayHealpixTemp(Dataset):\n",
    "    \n",
    "    \"\"\" Dataset used for graph models (1D), where data is loaded from stored numpy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray Dataset\n",
    "        Dataset containing the input data\n",
    "    out_features : int\n",
    "        Number of output features\n",
    "    delta_t : int\n",
    "        Temporal spacing between samples in temporal sequence (in hours)\n",
    "    len_sqce : int\n",
    "        Length of the input and output (predicted) sequences\n",
    "    years : tuple(str)\n",
    "        Years used to split the data\n",
    "    nodes : float\n",
    "        Number of nodes each sample has\n",
    "    max_lead_time : int\n",
    "        Maximum lead time (in case of iterative predictions) in hours\n",
    "    load : bool\n",
    "        If true, load dataset to RAM\n",
    "    mean : np.ndarray of shape 2\n",
    "        Mean to use for data normalization. If None, mean is computed from data\n",
    "    std : np.ndarray of shape 2\n",
    "        std to use for data normalization. If None, mean is computed from data\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, ds, out_features, delta_t, len_sqce, years, nodes, nb_timesteps, \n",
    "                 max_lead_time=None, load=True, mean=None, std=None):\n",
    "        \n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        self.len_sqce = len_sqce\n",
    "        self.years = years\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.out_features = out_features\n",
    "        self.max_lead_time = max_lead_time\n",
    "        self.nb_timesteps = nb_timesteps\n",
    "        \n",
    "        self.data = ds.to_array(dim='level', name='Dataset').transpose('time', 'node', 'level')\n",
    "        self.in_features = self.data.shape[-1]\n",
    "        \n",
    "        self.mean = self.data.mean(('time', 'node')).compute() if mean is None else mean\n",
    "        self.std = self.data.std(('time', 'node')).compute() if std is None else std\n",
    "        \n",
    "        eps = 0.001 #add to std to avoid division by 0\n",
    "        \n",
    "        # Count total number of samples\n",
    "        total_samples = self.data.shape[0]        \n",
    "        \n",
    "        if max_lead_time is None:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t\n",
    "        else:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t - max_lead_time\n",
    "        \n",
    "        # Normalize\n",
    "        self.data = (self.data - self.mean.to_array(dim='level')) / (self.std.to_array(dim='level') + eps)\n",
    "        self.data.persist()\n",
    "        \n",
    "        self.idxs = np.array(range(self.n_samples))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, len_sqce, n_features]\n",
    "            \n",
    "        \"\"\"\n",
    "        idx_data = idx#self.idxs[idx]\n",
    "        #1,0,2\n",
    "        \n",
    "        #batch[0] --> (batch_size, num_nodes, n_features*len_sq)\n",
    "        idx_full = np.concatenate([idx_data+delta_t,  idx_data + delta_t * len_sqce, idx_data + delta_t * (len_sqce+1)])\n",
    "        dat = self.data.isel(time=idx_full).values\n",
    "        \n",
    "        \n",
    "        X = (\n",
    "            torch.tensor(dat[:len(idx),:,:] , \\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1),\n",
    "        )\n",
    "        \n",
    "        y = (torch.tensor(dat[len(idx):len(idx)*2,:,:],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1),\\\n",
    "             torch.tensor(dat[len(idx)*2:,:,:out_features],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        \n",
    "        )\n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```standardization_contants``` is a boolean that will enable the creation of a file that contains the constants already standardized. Set to True only if it is the first time executing the notebook or the file was lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_contants = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if standardization_contants:\n",
    "    constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg.nc').rename({'orography' :'orog'})\n",
    "    constants = constants.assign(cos_lon=lambda x: np.cos(np.deg2rad(x.lon)))\n",
    "    constants = constants.assign(sin_lon=lambda x: np.sin(np.deg2rad(x.lon)))\n",
    "    \n",
    "    constants_mean = constants.mean().compute()\n",
    "    constants_std = constants.std().compute()\n",
    "    \n",
    "    constants_mean.to_netcdf(f'{input_dir}constants/mean.nc')\n",
    "    constants_std.to_netcdf(f'{input_dir}constants/std.nc')\n",
    "    \n",
    "    c_mean = xr.open_dataset(f'{input_dir}constants/mean.nc')\n",
    "    c_std = xr.open_dataset(f'{input_dir}constants/std.nc')\n",
    "    \n",
    "    constants_ss = (constants - c_mean)/c_std\n",
    "    \n",
    "    constants_ss.to_netcdf(f'{input_dir}constants/constants_5.625deg_standardized.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'z':'z500'})\n",
    "t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'t':'t850'})\n",
    "rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords', chunks={'time':chunk_size})\n",
    "\n",
    "z500 = z500.isel(time=slice(7, None))\n",
    "t850 = t850.isel(time=slice(7, None))\n",
    "\n",
    "constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg_standardized.nc')\n",
    "#constants = constants.assign(cos_lon=lambda x: np.cos(np.deg2rad(x.lon)))\n",
    "#constants = constants.assign(sin_lon=lambda x: np.sin(np.deg2rad(x.lon)))\n",
    "\n",
    "#temp = xr.DataArray(np.zeros(z500.dims['time']), coords=[('time', z500.time.values)])\n",
    "#constants, _ = xr.broadcast(constants, temp)\n",
    "\n",
    "orog = constants['orog']\n",
    "lsm = constants['lsm']\n",
    "lats = constants['lat2d']\n",
    "slt = constants['slt']\n",
    "cos_lon = constants['cos_lon']\n",
    "sin_lon = constants['sin_lon']\n",
    "\n",
    "num_constants = len([orog, lats, lsm, slt])\n",
    "constants_tensor = torch.tensor(xr.merge([orog, lats, lsm, slt], compat='override').to_array().values, \\\n",
    "                            dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description = \"no_const\"\n",
    "description = \"all_const\"\n",
    "\n",
    "model_filename = model_save_path + \"spherical_unet_\" + description + \".h5\"\n",
    "pred_filename = pred_save_path + \"spherical_unet_\" + description + \".nc\"\n",
    "rmse_filename = datadir + 'metrics/rmse_' + description + '.nc'\n",
    "\n",
    "# z500, t850, orog, lats, lsm, slt, rad\n",
    "#feature_idx = [0, 1]\n",
    "in_features = 7 #len(feature_idx)\n",
    "ds = xr.merge([z500, t850, rad], compat='override')\n",
    "#ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "\n",
    "ds_train = ds.sel(time=slice(*train_years))\n",
    "ds_valid = ds.sel(time=slice(*val_years))\n",
    "ds_test = ds.sel(time=slice(*test_years))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if standardization_contants:\n",
    "    mean_features = ds_train.mean(('time','node')).compute()\n",
    "    std_features = ds_train.std('time').mean('node').compute()\n",
    "\n",
    "    mean_features.to_netcdf(f'{input_dir}mean_train_features_dynamic.nc')\n",
    "    std_features.to_netcdf(f'{input_dir}std_train_features_dynamic.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_ = xr.open_mfdataset(f'{input_dir}mean_train_features_dynamic.nc')\n",
    "train_std_ = xr.open_mfdataset(f'{input_dir}std_train_features_dynamic.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation data\n",
    "training_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_train, out_features=out_features, delta_t=delta_t,\n",
    "                                                   len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                   years=train_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                   mean=train_mean_, std=train_std_, load=False)\n",
    "validation_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_valid, out_features=out_features, delta_t=delta_t,\n",
    "                                                     len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                     years=val_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                     mean=train_mean_, std=train_std_, load=False)\n",
    "\n",
    "dl_train = DataLoader(training_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers,\\\n",
    "                      pin_memory=pin_memory)\n",
    "\n",
    "dl_val = DataLoader(validation_ds, batch_size=batch_size*2, shuffle=False, num_workers=num_workers,\\\n",
    "                    pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #old: in_channels=in_features*len_sqce\n",
    "spherical_unet = UNetSphericalHealpix(N=nodes, in_channels=in_features, out_channels=out_features, \n",
    "                                      kernel_size=3)\n",
    "spherical_unet, device = init_device(spherical_unet, gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2steps_custom(model, device, training_ds, constants, batch_size, epochs, lr, validation_ds):    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    n_samples = training_ds.n_samples\n",
    "    n_samples_val = validation_ds.n_samples\n",
    "    num_nodes = training_ds.nodes\n",
    "    num_constants = constants.shape[1]\n",
    "    out_features = training_ds.out_features\n",
    "    \n",
    "    constants_expanded = constants.expand(batch_size, num_nodes, num_constants)\n",
    "    constants1 = constants_expanded.to(device)\n",
    "    idxs_val = validation_ds.idxs\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('\\rEpoch : {}'.format(epoch), end=\"\")\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()  \n",
    "        \n",
    "        random.shuffle(training_ds.idxs)\n",
    "        idxs = training_ds.idxs\n",
    "        \n",
    "        batch_idx = 0\n",
    "        \n",
    "        for i in range(0, n_samples - batch_size, batch_size):\n",
    "            i_next = min(i + batch_size, n_samples)\n",
    "            \n",
    "            if len(idxs[i:i_next]) < batch_size:\n",
    "                constants_expanded = contants.expand(len(idxs[i:i_next]), num_nodes, num_constants)\n",
    "                constants1 = constants_expanded.to(device)\n",
    "        \n",
    "            \n",
    "            #t1 = time.time()\n",
    "            batch, labels = training_ds[idxs[i:i_next]]\n",
    "            \n",
    "            #t2 = time.time()\n",
    "            \n",
    "            # Transfer to GPU\n",
    "            \n",
    "            \n",
    "            batch1 = torch.cat((batch[0], constants_expanded), dim=2).to(device)\n",
    "            label1 = labels[0].to(device)\n",
    "            label2 = labels[1].to(device)\n",
    "            \n",
    "            \n",
    "            #t3 = time.time()\n",
    "            batch_size = batch1.shape[0]\n",
    "            \n",
    "            # Model\n",
    "            \n",
    "            #t4 = time.time()\n",
    "            output1 = model(batch1)  \n",
    "            #t5 = time.time()\n",
    "            batch2 = torch.cat((output1, label1[:,:,-1].view(-1, num_nodes, 1), constants1), dim=2)\n",
    "            #t6 = time.time()\n",
    "            output2 = model(batch2)\n",
    "            #t7 = time.time()\n",
    "            loss = criterion(output1, label1[:,:,:out_features]) + criterion(output2, label2)\n",
    "            #t8 = time.time()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * batch_size\n",
    "            \n",
    "            \n",
    "            #print('\\nTime to read batch: {}s'.format(t2-t1))\n",
    "            #print('Time to transfer data to GPU: {}s'.format(t3-t2))\n",
    "            #print('Time to process input 1: {}s'.format(t5-t4))\n",
    "            #print('Time to process input 2: {}s'.format(t7-t6))\n",
    "            #print('Time to compute loss: {}s'.format(t8-t7))\n",
    "            #print('\\n')\n",
    "            print('\\rBatch idx: {}; Loss: {:.3f}'.format(batch_idx, train_loss/(batch_size*(batch_idx+1))), end=\"\")\n",
    "            batch_idx += 1\n",
    "        \n",
    "        train_loss = train_loss / n_samples\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        constants1 = constants_expanded.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            index = 0\n",
    "            \n",
    "            for i in range(0, n_samples_val - batch_size, batch_size):\n",
    "                i_next = min(i + batch_size, n_samples_val)\n",
    "\n",
    "                if len(idxs_val[i:i_next]) < batch_size:\n",
    "                    constants_expanded = contants.expand(len(idxs_val[i:i_next]), num_nodes, num_constants)\n",
    "                    constants1 = constants_expanded.to(device)\n",
    "\n",
    "\n",
    "                #t1 = time.time()\n",
    "                batch, labels = validation_ds[idxs_val[i:i_next]]\n",
    "                # Transfer to GPU\n",
    "                batch1 = torch.cat((batch[0], constants_expanded), dim=2).to(device)\n",
    "                label1 = labels[0].to(device)\n",
    "                label2 = labels[1].to(device)\n",
    "\n",
    "                batch_size = batch1.shape[0]\n",
    "                \n",
    "                output1 = model(batch1)\n",
    "                batch2 = torch.cat((output1, label1[:,:,-1].view(-1, num_nodes, 1), constants1), dim=2)\n",
    "                output2 = model(batch2)\n",
    "                \n",
    "                val_loss = val_loss + (criterion(output1, label1[:,:,:out_features]).item() \n",
    "                                       + criterion(output2, label2).item()) * batch_size\n",
    "                index = index + batch_size\n",
    "                \n",
    "        val_loss = val_loss / n_samples_val\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch idx: 3134; Loss: 0.146Epoch:   1/  7  - loss: 0.146  - val_loss: 0.08996  - time: 9112.442816\n",
      "Batch idx: 3134; Loss: 0.067Epoch:   2/  7  - loss: 0.067  - val_loss: 0.07784  - time: 8952.762427\n",
      "Batch idx: 3134; Loss: 0.059Epoch:   3/  7  - loss: 0.059  - val_loss: 0.06506  - time: 9087.411525\n",
      "Batch idx: 3134; Loss: 0.055Epoch:   4/  7  - loss: 0.055  - val_loss: 0.06146  - time: 9108.357737\n",
      "Batch idx: 3134; Loss: 0.052Epoch:   5/  7  - loss: 0.052  - val_loss: 0.05875  - time: 9163.751619\n",
      "Batch idx: 3134; Loss: 0.051Epoch:   6/  7  - loss: 0.051  - val_loss: 0.06549  - time: 8639.539581\n",
      "Batch idx: 3134; Loss: 0.050Epoch:   7/  7  - loss: 0.050  - val_loss: 0.09280  - time: 7845.371900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.14609487630704313,\n",
       "  0.06691656585619492,\n",
       "  0.05884525018606003,\n",
       "  0.05463608803415421,\n",
       "  0.05232742307901584,\n",
       "  0.05091046646963797,\n",
       "  0.049796112792113253],\n",
       " [0.0899640527970213,\n",
       "  0.07783917889697838,\n",
       "  0.06505507764545217,\n",
       "  0.06146494293280259,\n",
       "  0.058750781663517763,\n",
       "  0.06549294110768775,\n",
       "  0.09280043438659136])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_2steps_custom(spherical_unet, device, training_ds, constants_tensor.transpose(1,0), batch_size, epochs=7, \\\n",
    "                                           lr=learning_rate, validation_ds=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [0.14609487630704313,\n",
    "  0.06691656585619492,\n",
    "  0.05884525018606003,\n",
    "  0.05463608803415421,\n",
    "  0.05232742307901584,\n",
    "  0.05091046646963797,\n",
    "  0.049796112792113253]\n",
    "\n",
    "val_loss = [0.0899640527970213,\n",
    "  0.07783917889697838,\n",
    "  0.06505507764545217,\n",
    "  0.06146494293280259,\n",
    "  0.058750781663517763,\n",
    "  0.06549294110768775,\n",
    "  0.09280043438659136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(spherical_unet.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression level:  0\n"
     ]
    }
   ],
   "source": [
    "z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'z':'z500'})\n",
    "print('compression level: ', z500['z500'].encoding.get('complevel', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
