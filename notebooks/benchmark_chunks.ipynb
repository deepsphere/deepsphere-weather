{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check influence of different parameters in performance. \n",
    "\n",
    "Check influence of:\n",
    "- specifying different chunk sizes and chunking along different dimensions\n",
    "- use already standardized data --> does it save memory?\n",
    "- use ``` .persist()``` to load data in a distributed way and speed up reading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import healpy as hp\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.utils import train_model_2steps, init_device\n",
    "from modules.data import WeatherBenchDatasetXarrayHealpix\n",
    "from modules.healpix_models import UNetSphericalHealpix\n",
    "from modules.test import create_iterative_predictions_healpix\n",
    "from modules.test import compute_rmse_healpix\n",
    "from modules.plotting import plot_rmses\n",
    "\n",
    "datadir = \"../data/healpix/\"\n",
    "input_dir = datadir + \"5.625deg_nearest/\"\n",
    "model_save_path = datadir + \"models/\"\n",
    "pred_save_path = datadir + \"predictions/\"\n",
    "\n",
    "train_years = ('1979', '2012')\n",
    "val_years = ('2013', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "nodes = 12*16*16\n",
    "max_lead_time = 5*24\n",
    "lead_time = 6\n",
    "out_features = 2\n",
    "nb_timesteps = 2\n",
    "len_sqce = 2\n",
    "# define time resolution\n",
    "delta_t = 6\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,4\"\n",
    "gpu = [0,1]\n",
    "num_workers = 10\n",
    "pin_memory = True\n",
    "batch_size = 95\n",
    "\n",
    "nb_epochs = 10\n",
    "learning_rate = 8e-3\n",
    "\n",
    "obs = xr.open_mfdataset(pred_save_path + 'observations_nearest.nc', combine='by_coords', chunks={'time':483})\n",
    "#rmses_weyn = xr.open_dataset(datadir + 'metrics/rmses_weyn.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import WeatherBenchDatasetIterative\n",
    "class WeatherBenchDatasetXarrayHealpixTemp(Dataset):\n",
    "    \n",
    "    \"\"\" Dataset used for graph models (1D), where data is loaded from stored numpy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray Dataset\n",
    "        Dataset containing the input data\n",
    "    out_features : int\n",
    "        Number of output features\n",
    "    delta_t : int\n",
    "        Temporal spacing between samples in temporal sequence (in hours)\n",
    "    len_sqce : int\n",
    "        Length of the input and output (predicted) sequences\n",
    "    years : tuple(str)\n",
    "        Years used to split the data\n",
    "    nodes : float\n",
    "        Number of nodes each sample has\n",
    "    max_lead_time : int\n",
    "        Maximum lead time (in case of iterative predictions) in hours\n",
    "    load : bool\n",
    "        If true, load dataset to RAM\n",
    "    mean : np.ndarray of shape 2\n",
    "        Mean to use for data normalization. If None, mean is computed from data\n",
    "    std : np.ndarray of shape 2\n",
    "        std to use for data normalization. If None, mean is computed from data\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, ds, out_features, delta_t, len_sqce, years, nodes, nb_timesteps, \n",
    "                 max_lead_time=None, load=True, mean=None, std=None):\n",
    "        \n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        self.len_sqce = len_sqce\n",
    "        self.years = years\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.out_features = out_features\n",
    "        self.max_lead_time = max_lead_time\n",
    "        self.nb_timesteps = nb_timesteps\n",
    "        \n",
    "        self.data = ds.to_array(dim='level', name='Dataset').transpose('time', 'node', 'level')\n",
    "        self.in_features = self.data.shape[-1]\n",
    "        \n",
    "        self.mean = self.data.mean(('time', 'node')).compute() if mean is None else mean\n",
    "        self.std = self.data.std(('time', 'node')).compute() if std is None else std\n",
    "        \n",
    "        eps = 0.001 #add to std to avoid division by 0\n",
    "        \n",
    "        # Count total number of samples\n",
    "        total_samples = self.data.shape[0]        \n",
    "        \n",
    "        if max_lead_time is None:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t\n",
    "        else:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t - max_lead_time\n",
    "        \n",
    "        # Normalize\n",
    "        self.data = (self.data - self.mean.to_array(dim='level')) / (self.std.to_array(dim='level') + eps)\n",
    "        \n",
    "        self.data.persist()\n",
    "        # Create indexes\n",
    "        #self.idxs = [[[[sample_idx + delta_t*k for k in range(len_sqce)], sample_idx + delta_t * len_sqce], \n",
    "        #              [sample_idx + delta_t * len_sqce, sample_idx + delta_t * (len_sqce+1)]] \n",
    "        #             for sample_idx in range(self.n_samples)]\n",
    "        \n",
    "        self.idxs = np.array(range(self.n_samples))\n",
    "        \n",
    "        \n",
    "        #if load: \n",
    "        #    print('Loading data into RAM')\n",
    "        #    self.data.load()\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, len_sqce, n_features]\n",
    "            \n",
    "            X = (\n",
    "            torch.tensor([self.data.isel(time=[idx_d + self.delta_t*k for k in range(self.len_sqce)]).values for idx_d in idx_data], \\\n",
    "                         dtype=torch.float).permute(0, 2,1,3).reshape(len(idx), self.nodes, -1),\\\n",
    "            \n",
    "             torch.tensor([self.data.isel(time=[idx_d + self.delta_t * self.len_sqce]).values[:,:,self.out_features:] for idx_d in idx_data],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        )\n",
    "        \n",
    "        X = (\n",
    "            torch.tensor([self.data.isel(time=[idx_d + self.delta_t]).values for idx_d in idx_data], \\\n",
    "                         dtype=torch.float).permute(0, 2,1,3).reshape(len(idx), self.nodes, -1),\\\n",
    "            \n",
    "             torch.tensor([self.data.isel(time=[idx_d + self.delta_t * self.len_sqce]).values[:,:,self.out_features:] for idx_d in idx_data],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        )\n",
    "        \n",
    "        y = ( torch.tensor([self.data.isel(time=[idx_d + self.delta_t * self.len_sqce]).values[:,:,:self.out_features] for idx_d in idx_data],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1), \n",
    "             torch.tensor([self.data.isel(time=[idx_d + self.delta_t * (self.len_sqce+1)]).values[:,:,:self.out_features] for idx_d in idx_data],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        \n",
    "        )\n",
    "        \"\"\"\n",
    "        idx_data = self.idxs[idx]\n",
    "        #1,0,2\n",
    "        \n",
    "        #batch[0] --> (batch_size, num_nodes, n_features*len_sq)\n",
    "        idx_full = np.concatenate([idx_data+delta_t,  idx_data + delta_t * len_sqce, idx_data + delta_t * (len_sqce+1)])\n",
    "        dat = self.data.isel(time=idx_full).values\n",
    "        \n",
    "        x2 = dat[len(idx):len(idx)*2,:,:]\n",
    "        \n",
    "        X = (\n",
    "            torch.tensor(dat[:len(idx),:,:] , \\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1),\\\n",
    "            \n",
    "             torch.tensor(x2[:,:,self.out_features:],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        )\n",
    "        \n",
    "        y = ( torch.tensor(x2[:,:,:self.out_features],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1), \n",
    "             torch.tensor(dat[len(idx)*2:,:,:out_features],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        \n",
    "        )\n",
    "        \n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'z':'z500'})\n",
    "t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords', chunks={'time':chunk_size}).rename({'t':'t850'})\n",
    "rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords', chunks={'time':chunk_size})\n",
    "\n",
    "z500 = z500.isel(time=slice(7, None))\n",
    "t850 = t850.isel(time=slice(7, None))\n",
    "\n",
    "constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg.nc').rename({'orography' :'orog'})\n",
    "constants = constants.assign(cos_lon=lambda x: np.cos(np.deg2rad(x.lon)))\n",
    "constants = constants.assign(sin_lon=lambda x: np.sin(np.deg2rad(x.lon)))\n",
    "\n",
    "temp = xr.DataArray(np.zeros(z500.dims['time']), coords=[('time', z500.time.values)])\n",
    "constants, _ = xr.broadcast(constants, temp)\n",
    "\n",
    "orog = constants['orog']\n",
    "lsm = constants['lsm']\n",
    "lats = constants['lat2d']\n",
    "slt = constants['slt']\n",
    "cos_lon = constants['cos_lon']\n",
    "sin_lon = constants['sin_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description = \"no_const\"\n",
    "description = \"all_const\"\n",
    "\n",
    "model_filename = model_save_path + \"spherical_unet_\" + description + \".h5\"\n",
    "pred_filename = pred_save_path + \"spherical_unet_\" + description + \".nc\"\n",
    "rmse_filename = datadir + 'metrics/rmse_' + description + '.nc'\n",
    "\n",
    "# z500, t850, orog, lats, lsm, slt, rad\n",
    "#feature_idx = [0, 1]\n",
    "in_features = 7 #len(feature_idx)\n",
    "#ds = xr.merge([z500, t850], compat='override')\n",
    "ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "\n",
    "ds_train = ds.sel(time=slice(*train_years))\n",
    "ds_valid = ds.sel(time=slice(*val_years))\n",
    "ds_test = ds.sel(time=slice(*test_years))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_ = xr.open_mfdataset(f'{input_dir}mean_train_all_const.nc')\n",
    "train_std_ = xr.open_mfdataset(f'{input_dir}std_train_all_const.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation data\n",
    "training_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_train, out_features=out_features, delta_t=delta_t,\n",
    "                                                   len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                   years=train_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                   mean=train_mean_, std=train_std_, load=False)\n",
    "validation_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_valid, out_features=out_features, delta_t=delta_t,\n",
    "                                                     len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                     years=train_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                     mean=train_mean_, std=train_std_, load=False)\n",
    "\n",
    "dl_train = DataLoader(training_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers,\\\n",
    "                      pin_memory=pin_memory)\n",
    "\n",
    "dl_val = DataLoader(validation_ds, batch_size=batch_size*2, shuffle=False, num_workers=num_workers,\\\n",
    "                    pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #old: in_channels=in_features*len_sqce\n",
    "spherical_unet = UNetSphericalHealpix(N=nodes, in_channels=in_features, out_channels=out_features, \n",
    "                                      kernel_size=3)\n",
    "spherical_unet, device = init_device(spherical_unet, gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2steps_custom(model, device, training_ds, batch_size, epochs, lr, validation_data):    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    n_samples = training_ds.n_samples\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('\\rEpoch : {}'.format(epoch), end=\"\")\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()  \n",
    "        \n",
    "        random.shuffle(training_ds.idxs)\n",
    "        idxs = training_ds.idxs\n",
    "        \n",
    "        batch_idx = 0\n",
    "        for i in range(0, n_samples - batch_size, batch_size):\n",
    "            i_next = min(i + batch_size, n_samples)\n",
    "        # for batch_idx, (batch, labels) in enumerate(train_generator):\n",
    "            t1 = time.time()\n",
    "            batch, labels = training_ds[idxs[i:i_next]]\n",
    "            t2 = time.time()\n",
    "            \n",
    "            # Transfer to GPU\n",
    "            batch1 = batch[0].to(device) #shape: input:(batch_size, num_nodes, num_features);\n",
    "            constants1 = batch[1].to(device) #shape: input:(batch_size, num_nodes, num_features - 2); 2: z500, T850\n",
    "            label1 = labels[0].to(device)\n",
    "            label2 = labels[1].to(device)\n",
    "            \n",
    "            t3 = time.time()\n",
    "            batch_size = batch1.shape[0]\n",
    "            \n",
    "            # Model\n",
    "            \n",
    "            t4 = time.time()\n",
    "            output1 = model(batch1)  \n",
    "            t5 = time.time()\n",
    "            batch2 = torch.cat((output1, constants1), dim=2)\n",
    "            t6 = time.time()\n",
    "            output2 = model(batch2)\n",
    "            t7 = time.time()\n",
    "            loss = criterion(output1, label1) + criterion(output2, label2)\n",
    "            t8 = time.time()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * batch_size\n",
    "            \n",
    "            \n",
    "            print('\\nTime to read batch: {}s'.format(t2-t1))\n",
    "            print('Time to transfer data to GPU: {}s'.format(t3-t2))\n",
    "            print('Time to process input 1: {}s'.format(t5-t4))\n",
    "            print('Time to process input 2: {}s'.format(t7-t6))\n",
    "            print('Time to compute loss: {}s'.format(t8-t7))\n",
    "            print('\\n')\n",
    "            print('\\rBatch idx: {}; Loss: {:.3f}'.format(batch_idx, train_loss/(batch_size*(batch_idx+1))), end=\"\")\n",
    "            batch_idx += 1\n",
    "            \n",
    "        if epoch == 2:\n",
    "            return output1, output2, label1, label2\n",
    "        \n",
    "        train_loss = train_loss / (len(train_generator.dataset))\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            index = 0\n",
    "            \n",
    "            for batch, labels in validation_data:\n",
    "                # Transfer to GPU\n",
    "                batch1 = batch[0].to(device)\n",
    "                constants1 = batch[1].to(device)\n",
    "                label1 = labels[0].to(device)\n",
    "                label2 = labels[1].to(device)\n",
    "\n",
    "                batch_size = batch1.shape[0]\n",
    "                \n",
    "                output1 = model(batch1)\n",
    "                batch2 = torch.cat((output1, constants1), dim=2)\n",
    "                output2 = model(batch2)\n",
    "                \n",
    "                val_loss = val_loss + (criterion(output1, label1).item() \n",
    "                                       + criterion(output2, label2).item()) * batch_size\n",
    "                index = index + batch_size\n",
    "                \n",
    "        val_loss = val_loss / (len(validation_data.dataset))\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 3.0518033504486084s\n",
      "Time to transfer data to GPU: 0.00491023063659668s\n",
      "Time to process input 1: 2.4747016429901123s\n",
      "Time to process input 2: 0.10156083106994629s\n",
      "Time to compute loss: 0.053165435791015625s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 18.084\n",
      "Time to read batch: 3.1848251819610596s\n",
      "Time to transfer data to GPU: 0.004255771636962891s\n",
      "Time to process input 1: 0.04463791847229004s\n",
      "Time to process input 2: 0.04043865203857422s\n",
      "Time to compute loss: 0.1611342430114746s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 16.544\n",
      "Time to read batch: 2.8995766639709473s\n",
      "Time to transfer data to GPU: 0.005391359329223633s\n",
      "Time to process input 1: 0.04396319389343262s\n",
      "Time to process input 2: 0.044149160385131836s\n",
      "Time to compute loss: 0.14213848114013672s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 14.724\n",
      "Time to read batch: 3.328223466873169s\n",
      "Time to transfer data to GPU: 0.004277467727661133s\n",
      "Time to process input 1: 0.03786420822143555s\n",
      "Time to process input 2: 0.03802299499511719s\n",
      "Time to compute loss: 0.15324139595031738s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 12.990\n",
      "Time to read batch: 2.9721028804779053s\n",
      "Time to transfer data to GPU: 0.005457162857055664s\n",
      "Time to process input 1: 0.041521549224853516s\n",
      "Time to process input 2: 0.03640556335449219s\n",
      "Time to compute loss: 0.1541745662689209s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 11.668\n",
      "Time to read batch: 3.2475650310516357s\n",
      "Time to transfer data to GPU: 0.004519939422607422s\n",
      "Time to process input 1: 0.03726673126220703s\n",
      "Time to process input 2: 0.036812782287597656s\n",
      "Time to compute loss: 0.154097318649292s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 10.550\n",
      "Time to read batch: 3.046771287918091s\n",
      "Time to transfer data to GPU: 0.004324674606323242s\n",
      "Time to process input 1: 0.04339885711669922s\n",
      "Time to process input 2: 0.03984546661376953s\n",
      "Time to compute loss: 0.14413857460021973s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 9.637\n",
      "Time to read batch: 3.174152135848999s\n",
      "Time to transfer data to GPU: 0.004300355911254883s\n",
      "Time to process input 1: 0.03832602500915527s\n",
      "Time to process input 2: 0.039319753646850586s\n",
      "Time to compute loss: 0.15166306495666504s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 8.901\n",
      "Time to read batch: 3.112436294555664s\n",
      "Time to transfer data to GPU: 0.004308223724365234s\n",
      "Time to process input 1: 0.03852581977844238s\n",
      "Time to process input 2: 0.03886675834655762s\n",
      "Time to compute loss: 0.15123414993286133s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 8.364\n",
      "Time to read batch: 3.7873640060424805s\n",
      "Time to transfer data to GPU: 0.00460362434387207s\n",
      "Time to process input 1: 0.040682315826416016s\n",
      "Time to process input 2: 0.03669571876525879s\n",
      "Time to compute loss: 0.15369844436645508s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 7.919\n",
      "Time to read batch: 2.9142532348632812s\n",
      "Time to transfer data to GPU: 0.00457310676574707s\n",
      "Time to process input 1: 0.041657209396362305s\n",
      "Time to process input 2: 0.04148554801940918s\n",
      "Time to compute loss: 0.14700746536254883s\n",
      "\n",
      "\n",
      "Batch idx: 10; Loss: 7.554\n",
      "Time to read batch: 3.4363162517547607s\n",
      "Time to transfer data to GPU: 0.004240274429321289s\n",
      "Time to process input 1: 0.03828239440917969s\n",
      "Time to process input 2: 0.036338090896606445s\n",
      "Time to compute loss: 0.1549057960510254s\n",
      "\n",
      "\n",
      "Batch idx: 11; Loss: 7.243\n",
      "Time to read batch: 3.0245590209960938s\n",
      "Time to transfer data to GPU: 0.004304647445678711s\n",
      "Time to process input 1: 0.03789782524108887s\n",
      "Time to process input 2: 0.03571772575378418s\n",
      "Time to compute loss: 0.15423822402954102s\n",
      "\n",
      "\n",
      "Batch idx: 12; Loss: 6.968\n",
      "Time to read batch: 3.3537683486938477s\n",
      "Time to transfer data to GPU: 0.004397392272949219s\n",
      "Time to process input 1: 0.04098081588745117s\n",
      "Time to process input 2: 0.03715777397155762s\n",
      "Time to compute loss: 0.15997314453125s\n",
      "\n",
      "\n",
      "Batch idx: 13; Loss: 6.724\n",
      "Time to read batch: 3.1522443294525146s\n",
      "Time to transfer data to GPU: 0.0041675567626953125s\n",
      "Time to process input 1: 0.03824615478515625s\n",
      "Time to process input 2: 0.042902469635009766s\n",
      "Time to compute loss: 0.14778399467468262s\n",
      "\n",
      "\n",
      "Batch idx: 14; Loss: 6.507\n",
      "Time to read batch: 3.122241497039795s\n",
      "Time to transfer data to GPU: 0.004208087921142578s\n",
      "Time to process input 1: 0.03704476356506348s\n",
      "Time to process input 2: 0.04423189163208008s\n",
      "Time to compute loss: 0.14749741554260254s\n",
      "\n",
      "\n",
      "Batch idx: 15; Loss: 6.308\n",
      "Time to read batch: 2.8175089359283447s\n",
      "Time to transfer data to GPU: 0.0042684078216552734s\n",
      "Time to process input 1: 0.036467552185058594s\n",
      "Time to process input 2: 0.050391435623168945s\n",
      "Time to compute loss: 0.14063525199890137s\n",
      "\n",
      "\n",
      "Batch idx: 16; Loss: 6.134\n",
      "Time to read batch: 3.1947731971740723s\n",
      "Time to transfer data to GPU: 0.004268646240234375s\n",
      "Time to process input 1: 0.0378870964050293s\n",
      "Time to process input 2: 0.0423431396484375s\n",
      "Time to compute loss: 0.14769697189331055s\n",
      "\n",
      "\n",
      "Batch idx: 17; Loss: 5.976\n",
      "Time to read batch: 2.8945531845092773s\n",
      "Time to transfer data to GPU: 0.004251718521118164s\n",
      "Time to process input 1: 0.04123735427856445s\n",
      "Time to process input 2: 0.035463571548461914s\n",
      "Time to compute loss: 0.1511545181274414s\n",
      "\n",
      "\n",
      "Batch idx: 18; Loss: 5.845\n",
      "Time to read batch: 3.100592613220215s\n",
      "Time to transfer data to GPU: 0.004245281219482422s\n",
      "Time to process input 1: 0.03633570671081543s\n",
      "Time to process input 2: 0.037615299224853516s\n",
      "Time to compute loss: 0.15472197532653809s\n",
      "\n",
      "\n",
      "Batch idx: 19; Loss: 5.715\n",
      "Time to read batch: 3.2343032360076904s\n",
      "Time to transfer data to GPU: 0.00500798225402832s\n",
      "Time to process input 1: 0.0421445369720459s\n",
      "Time to process input 2: 0.038156747817993164s\n",
      "Time to compute loss: 0.1511096954345703s\n",
      "\n",
      "\n",
      "Batch idx: 20; Loss: 5.603\n",
      "Time to read batch: 3.075510263442993s\n",
      "Time to transfer data to GPU: 0.004312276840209961s\n",
      "Time to process input 1: 0.03867053985595703s\n",
      "Time to process input 2: 0.03720259666442871s\n",
      "Time to compute loss: 0.1535797119140625s\n",
      "\n",
      "\n",
      "Batch idx: 21; Loss: 5.503\n",
      "Time to read batch: 2.7420177459716797s\n",
      "Time to transfer data to GPU: 0.004288911819458008s\n",
      "Time to process input 1: 0.03813028335571289s\n",
      "Time to process input 2: 0.03673911094665527s\n",
      "Time to compute loss: 0.1523294448852539s\n",
      "\n",
      "\n",
      "Batch idx: 22; Loss: 5.417\n",
      "Time to read batch: 3.2387423515319824s\n",
      "Time to transfer data to GPU: 0.005465269088745117s\n",
      "Time to process input 1: 0.04320192337036133s\n",
      "Time to process input 2: 0.0503082275390625s\n",
      "Time to compute loss: 0.1398472785949707s\n",
      "\n",
      "\n",
      "Batch idx: 23; Loss: 5.338\n",
      "Time to read batch: 2.8843162059783936s\n",
      "Time to transfer data to GPU: 0.004361391067504883s\n",
      "Time to process input 1: 0.04173636436462402s\n",
      "Time to process input 2: 0.03567218780517578s\n",
      "Time to compute loss: 0.15251636505126953s\n",
      "\n",
      "\n",
      "Batch idx: 24; Loss: 5.264\n",
      "Time to read batch: 3.3479857444763184s\n",
      "Time to transfer data to GPU: 0.0043222904205322266s\n",
      "Time to process input 1: 0.04265785217285156s\n",
      "Time to process input 2: 0.039017438888549805s\n",
      "Time to compute loss: 0.1476445198059082s\n",
      "\n",
      "\n",
      "Batch idx: 25; Loss: 5.183\n",
      "Time to read batch: 2.8022308349609375s\n",
      "Time to transfer data to GPU: 0.004485368728637695s\n",
      "Time to process input 1: 0.04034852981567383s\n",
      "Time to process input 2: 0.03695988655090332s\n",
      "Time to compute loss: 0.1558213233947754s\n",
      "\n",
      "\n",
      "Batch idx: 26; Loss: 5.116\n",
      "Time to read batch: 3.4995667934417725s\n",
      "Time to transfer data to GPU: 0.004293203353881836s\n",
      "Time to process input 1: 0.038764238357543945s\n",
      "Time to process input 2: 0.03918862342834473s\n",
      "Time to compute loss: 0.1523287296295166s\n",
      "\n",
      "\n",
      "Batch idx: 27; Loss: 5.056\n",
      "Time to read batch: 2.7736451625823975s\n",
      "Time to transfer data to GPU: 0.0041904449462890625s\n",
      "Time to process input 1: 0.04146552085876465s\n",
      "Time to process input 2: 0.03686404228210449s\n",
      "Time to compute loss: 0.15001749992370605s\n",
      "\n",
      "\n",
      "Batch idx: 28; Loss: 4.997\n",
      "Time to read batch: 3.245711326599121s\n",
      "Time to transfer data to GPU: 0.005074024200439453s\n",
      "Time to process input 1: 0.04781460762023926s\n",
      "Time to process input 2: 0.03944206237792969s\n",
      "Time to compute loss: 0.14583683013916016s\n",
      "\n",
      "\n",
      "Batch idx: 29; Loss: 4.937\n",
      "Time to read batch: 2.5517616271972656s\n",
      "Time to transfer data to GPU: 0.009193658828735352s\n",
      "Time to process input 1: 0.03993368148803711s\n",
      "Time to process input 2: 0.03995990753173828s\n",
      "Time to compute loss: 0.1506667137145996s\n",
      "\n",
      "\n",
      "Batch idx: 30; Loss: 4.878\n",
      "Time to read batch: 3.0850043296813965s\n",
      "Time to transfer data to GPU: 0.004484891891479492s\n",
      "Time to process input 1: 0.043192386627197266s\n",
      "Time to process input 2: 0.03949451446533203s\n",
      "Time to compute loss: 0.14667391777038574s\n",
      "\n",
      "\n",
      "Batch idx: 31; Loss: 4.825\n",
      "Time to read batch: 2.7085888385772705s\n",
      "Time to transfer data to GPU: 0.004180908203125s\n",
      "Time to process input 1: 0.03655099868774414s\n",
      "Time to process input 2: 0.03824615478515625s\n",
      "Time to compute loss: 0.15402674674987793s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch idx: 32; Loss: 4.779\n",
      "Time to read batch: 3.506366014480591s\n",
      "Time to transfer data to GPU: 0.004374265670776367s\n",
      "Time to process input 1: 0.0395047664642334s\n",
      "Time to process input 2: 0.04399561882019043s\n",
      "Time to compute loss: 0.14551186561584473s\n",
      "\n",
      "\n",
      "Batch idx: 33; Loss: 4.732\n",
      "Time to read batch: 2.89284348487854s\n",
      "Time to transfer data to GPU: 0.00423884391784668s\n",
      "Time to process input 1: 0.03754448890686035s\n",
      "Time to process input 2: 0.0370485782623291s\n",
      "Time to compute loss: 0.15456199645996094s\n",
      "\n",
      "\n",
      "Batch idx: 34; Loss: 4.687\n",
      "Time to read batch: 3.351789712905884s\n",
      "Time to transfer data to GPU: 0.0041217803955078125s\n",
      "Time to process input 1: 0.0466768741607666s\n",
      "Time to process input 2: 0.0421147346496582s\n",
      "Time to compute loss: 0.14236021041870117s\n",
      "\n",
      "\n",
      "Batch idx: 35; Loss: 4.646\n",
      "Time to read batch: 2.635546922683716s\n",
      "Time to transfer data to GPU: 0.004257678985595703s\n",
      "Time to process input 1: 0.03563499450683594s\n",
      "Time to process input 2: 0.03734946250915527s\n",
      "Time to compute loss: 0.15666460990905762s\n",
      "\n",
      "\n",
      "Batch idx: 36; Loss: 4.607\n",
      "Time to read batch: 3.1635284423828125s\n",
      "Time to transfer data to GPU: 0.0043849945068359375s\n",
      "Time to process input 1: 0.038323163986206055s\n",
      "Time to process input 2: 0.03761863708496094s\n",
      "Time to compute loss: 0.15279483795166016s\n",
      "\n",
      "\n",
      "Batch idx: 37; Loss: 4.573\n",
      "Time to read batch: 2.8557493686676025s\n",
      "Time to transfer data to GPU: 0.004302501678466797s\n",
      "Time to process input 1: 0.03977513313293457s\n",
      "Time to process input 2: 0.038980960845947266s\n",
      "Time to compute loss: 0.15111708641052246s\n",
      "\n",
      "\n",
      "Batch idx: 38; Loss: 4.533\n",
      "Time to read batch: 3.0719566345214844s\n",
      "Time to transfer data to GPU: 0.0043849945068359375s\n",
      "Time to process input 1: 0.039467573165893555s\n",
      "Time to process input 2: 0.04358196258544922s\n",
      "Time to compute loss: 0.15617799758911133s\n",
      "\n",
      "\n",
      "Batch idx: 39; Loss: 4.501\n",
      "Time to read batch: 2.929823398590088s\n",
      "Time to transfer data to GPU: 0.004184722900390625s\n",
      "Time to process input 1: 0.035257816314697266s\n",
      "Time to process input 2: 0.036293745040893555s\n",
      "Time to compute loss: 0.1559300422668457s\n",
      "\n",
      "\n",
      "Batch idx: 40; Loss: 4.469\n",
      "Time to read batch: 3.281572103500366s\n",
      "Time to transfer data to GPU: 0.00515294075012207s\n",
      "Time to process input 1: 0.044670820236206055s\n",
      "Time to process input 2: 0.05203866958618164s\n",
      "Time to compute loss: 0.14025592803955078s\n",
      "\n",
      "\n",
      "Batch idx: 41; Loss: 4.442\n",
      "Time to read batch: 3.009127616882324s\n",
      "Time to transfer data to GPU: 0.00418543815612793s\n",
      "Time to process input 1: 0.033858299255371094s\n",
      "Time to process input 2: 0.037580013275146484s\n",
      "Time to compute loss: 0.15539240837097168s\n",
      "\n",
      "\n",
      "Batch idx: 42; Loss: 4.419\n",
      "Time to read batch: 2.9269347190856934s\n",
      "Time to transfer data to GPU: 0.004217624664306641s\n",
      "Time to process input 1: 0.03678178787231445s\n",
      "Time to process input 2: 0.04277992248535156s\n",
      "Time to compute loss: 0.1506655216217041s\n",
      "\n",
      "\n",
      "Batch idx: 43; Loss: 4.392\n",
      "Time to read batch: 3.0691113471984863s\n",
      "Time to transfer data to GPU: 0.004754066467285156s\n",
      "Time to process input 1: 0.038463592529296875s\n",
      "Time to process input 2: 0.04330277442932129s\n",
      "Time to compute loss: 0.15070104598999023s\n",
      "\n",
      "\n",
      "Batch idx: 44; Loss: 4.367\n",
      "Time to read batch: 2.9230568408966064s\n",
      "Time to transfer data to GPU: 0.005232572555541992s\n",
      "Time to process input 1: 0.04260897636413574s\n",
      "Time to process input 2: 0.03873181343078613s\n",
      "Time to compute loss: 0.15107989311218262s\n",
      "\n",
      "\n",
      "Batch idx: 45; Loss: 4.339\n",
      "Time to read batch: 3.0507864952087402s\n",
      "Time to transfer data to GPU: 0.00429224967956543s\n",
      "Time to process input 1: 0.03872394561767578s\n",
      "Time to process input 2: 0.03618025779724121s\n",
      "Time to compute loss: 0.1530454158782959s\n",
      "\n",
      "\n",
      "Batch idx: 46; Loss: 4.317\n",
      "Time to read batch: 2.994715690612793s\n",
      "Time to transfer data to GPU: 0.0042307376861572266s\n",
      "Time to process input 1: 0.03871583938598633s\n",
      "Time to process input 2: 0.038820743560791016s\n",
      "Time to compute loss: 0.1517963409423828s\n",
      "\n",
      "\n",
      "Batch idx: 47; Loss: 4.295\n",
      "Time to read batch: 3.1481971740722656s\n",
      "Time to transfer data to GPU: 0.004079580307006836s\n",
      "Time to process input 1: 0.03560757637023926s\n",
      "Time to process input 2: 0.03496289253234863s\n",
      "Time to compute loss: 0.15717434883117676s\n",
      "\n",
      "\n",
      "Batch idx: 48; Loss: 4.272\n",
      "Time to read batch: 3.0178825855255127s\n",
      "Time to transfer data to GPU: 0.004396200180053711s\n",
      "Time to process input 1: 0.04110097885131836s\n",
      "Time to process input 2: 0.03621411323547363s\n",
      "Time to compute loss: 0.15507912635803223s\n",
      "\n",
      "\n",
      "Batch idx: 49; Loss: 4.247\n",
      "Time to read batch: 3.0446436405181885s\n",
      "Time to transfer data to GPU: 0.0041654109954833984s\n",
      "Time to process input 1: 0.03679609298706055s\n",
      "Time to process input 2: 0.03658127784729004s\n",
      "Time to compute loss: 0.1554701328277588s\n",
      "\n",
      "\n",
      "Batch idx: 50; Loss: 4.220\n",
      "Time to read batch: 2.945233106613159s\n",
      "Time to transfer data to GPU: 0.004286766052246094s\n",
      "Time to process input 1: 0.03618574142456055s\n",
      "Time to process input 2: 0.037850141525268555s\n",
      "Time to compute loss: 0.15567922592163086s\n",
      "\n",
      "\n",
      "Batch idx: 51; Loss: 4.199\n",
      "Time to read batch: 3.479389190673828s\n",
      "Time to transfer data to GPU: 0.004279613494873047s\n",
      "Time to process input 1: 0.03975391387939453s\n",
      "Time to process input 2: 0.04319882392883301s\n",
      "Time to compute loss: 0.15575861930847168s\n",
      "\n",
      "\n",
      "Batch idx: 52; Loss: 4.180\n",
      "Time to read batch: 2.8006935119628906s\n",
      "Time to transfer data to GPU: 0.004246950149536133s\n",
      "Time to process input 1: 0.03933072090148926s\n",
      "Time to process input 2: 0.037889957427978516s\n",
      "Time to compute loss: 0.15385007858276367s\n",
      "\n",
      "\n",
      "Batch idx: 53; Loss: 4.163\n",
      "Time to read batch: 3.188013792037964s\n",
      "Time to transfer data to GPU: 0.0046541690826416016s\n",
      "Time to process input 1: 0.03949165344238281s\n",
      "Time to process input 2: 0.03794264793395996s\n",
      "Time to compute loss: 0.15173745155334473s\n",
      "\n",
      "\n",
      "Batch idx: 54; Loss: 4.144"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_release_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_release_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_thread.lock' object has no attribute '_release_save'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c296ae24bd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_model_2steps_custom(spherical_unet, device, training_ds, batch_size, epochs=7, \\\n\u001b[0;32m----> 2\u001b[0;31m                                            lr=learning_rate, validation_data=dl_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4bbc5cf001e5>\u001b[0m in \u001b[0;36mtrain_model_2steps_custom\u001b[0;34m(model, device, training_ds, batch_size, epochs, lr, validation_data)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# for batch_idx, (batch, labels) in enumerate(train_generator):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_next\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a2453d05401d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#batch[0] --> (batch_size, num_nodes, n_features*len_sq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0midx_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdelta_t\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0midx_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen_sqce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen_sqce\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;34m\"\"\"The array's data as a numpy.ndarray\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;34m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_as_array_or_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mTODO\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0monce\u001b[0m \u001b[0mthese\u001b[0m \u001b[0missues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"M\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                     \u001b[0mfire_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0msucceeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mfire_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m                         \u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     ),\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                 )\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, args, kwds, callback, error_callback)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pool not running\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApplyResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taskqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache, callback, error_callback)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# release() and acquire() on the lock).  Ditto for _is_owned().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_release_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_release_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model_2steps_custom(spherical_unet, device, training_ds, batch_size, epochs=7, \\\n",
    "                                           lr=learning_rate, validation_data=dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
