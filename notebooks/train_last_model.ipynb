{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model according to report to try to reproduce results\n",
    "\n",
    "- All static features: \n",
    "    * Z500, \n",
    "    * T850, \n",
    "    * latitude, \n",
    "    * orography, \n",
    "    * land-sea mask, \n",
    "    * soil type, and \n",
    "    * top-of-atmosphere radiation\n",
    "- L=2\n",
    "- $\\Delta t$ = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import healpy as hp\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.utils import train_model_2steps_temp, init_device\n",
    "from modules.data import WeatherBenchDatasetXarrayHealpixTemp\n",
    "from modules.healpix_models import UNetSphericalHealpix\n",
    "from modules.test import create_iterative_predictions_healpix_temp\n",
    "from modules.test import compute_rmse_healpix\n",
    "from modules.plotting import plot_rmses\n",
    "\n",
    "datadir = \"../data/healpix/\"\n",
    "input_dir = datadir + \"5.625deg/\"\n",
    "model_save_path = datadir + \"models/\"\n",
    "pred_save_path = datadir + \"predictions/\"\n",
    "\n",
    "if not os.path.isdir(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "if not os.path.isdir(pred_save_path):\n",
    "    os.mkdir(pred_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = ('2000', '2012')#('1979', '2012')\n",
    "val_years = ('2013', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "nodes = 12*16*16\n",
    "max_lead_time = 5*24\n",
    "nb_timesteps = 2\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,2\"\n",
    "gpu = [0, 1]\n",
    "num_workers = 10\n",
    "pin_memory = True\n",
    "\n",
    "nb_epochs = 20\n",
    "learning_rate = 8e-3\n",
    "\n",
    "obs = xr.open_mfdataset(pred_save_path + 'observations.nc', combine='by_coords')\n",
    "#rmses_weyn = xr.open_dataset(datadir + 'metrics/rmses_weyn.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions:\n",
    "\n",
    "**TODO**\n",
    "Check if the code is the same as the functions with the same name in ```modules/*.py``` and subtitute by imports in such a case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords').rename({'z':'z500'})\n",
    "t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords').rename({'t':'t850'})\n",
    "rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords')\n",
    "\n",
    "z500 = z500.isel(time=slice(7, None))\n",
    "t850 = t850.isel(time=slice(7, None))\n",
    "\n",
    "constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg.nc').rename({'orography' :'orog'})\n",
    "constants = constants.assign(cos_lon=lambda x: np.cos(np.deg2rad(x.lon)))\n",
    "constants = constants.assign(sin_lon=lambda x: np.sin(np.deg2rad(x.lon)))\n",
    "\n",
    "temp = xr.DataArray(np.zeros(z500.dims['time']), coords=[('time', z500.time.values)])\n",
    "constants, _ = xr.broadcast(constants, temp)\n",
    "\n",
    "orog = constants['orog']\n",
    "lsm = constants['lsm']\n",
    "lats = constants['lat2d']\n",
    "slt = constants['slt']\n",
    "cos_lon = constants['cos_lon']\n",
    "sin_lon = constants['sin_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords')['z']\\\n",
    ".assign_coords(level=1)\n",
    "\n",
    "t = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords')['t']\\\n",
    ".assign_coords(level=1)\n",
    "\n",
    "predictors = xr.concat([z, t], 'level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors_mean = predictors.mean(('time','node')).compute()\n",
    "#predictors_std = predictors.std('time').mean('node').compute()\n",
    "\n",
    "#const_mean = constants.mean(('time','node')).compute()\n",
    "#const_std = constants.std('time').mean(('node')).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z500, t850, orog, lats, lsm, slt, rad\n",
    "in_features = 7\n",
    "out_features = 2\n",
    "ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "\n",
    "ds_train = ds.sel(time=slice(*train_years))\n",
    "ds_valid = ds.sel(time=slice(*val_years))\n",
    "ds_test = ds.sel(time=slice(*test_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = ds_train.mean(('time','node')).compute()\n",
    "train_std = ds_train.std('time').mean('node').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define length of sequence to take into account for loss\n",
    "len_sqce = 2\n",
    "# define time resolution\n",
    "delta_t = 6\n",
    "\n",
    "# predict 5days data\n",
    "max_lead_time = 5*24\n",
    "\n",
    "feature_idx = list(range(7))\n",
    "in_features = 7\n",
    "out_features = 2\n",
    "#ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "#ds_test = ds.sel(time=slice(*test_years))\n",
    "\n",
    "#train_mean_ = train_mean.to_array()[feature_idx]\n",
    "#train_std_ = train_std.to_array()[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train_mean_\n",
    "#del train_std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sqce = 2\n",
    "delta_t = 6\n",
    "\n",
    "description = \"all_const_len{}_delta{}\".format(len_sqce, delta_t)\n",
    "\n",
    "model_filename = model_save_path + \"spherical_unet_\" + description + \".h5\"\n",
    "pred_filename = pred_save_path + \"spherical_unet_\" + description + \".nc\"\n",
    "rmse_filename = datadir + 'metrics/rmse_' + description + '.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention:**\n",
    "\n",
    "If ```load=True``` the kernel dies. Check problem origin and if it's necessary to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation data\n",
    "training_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_train, out_features=out_features,\n",
    "                                                   len_sqce=len_sqce, delta_t=delta_t, years=train_years,\n",
    "                                                   nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                   mean=train_mean, std=train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_valid, out_features=out_features, \n",
    "                                                     len_sqce=len_sqce, delta_t=delta_t, years=val_years, \n",
    "                                                     nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                     mean=train_mean, std=train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(training_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                      pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_val = DataLoader(validation_ds, batch_size=batch_size*2, shuffle=False, num_workers=num_workers, \n",
    "                    pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention:**\n",
    "\n",
    "Problem with ```pygsp.graphs``` since the module we are trying to load doesn't seem to appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "spherical_unet = UNetSphericalHealpix(N=nodes, in_channels=in_features*len_sqce, out_channels=out_features, \n",
    "                                      kernel_size=3)\n",
    "spherical_unet, device = init_device(spherical_unet, gpu=gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_loss, val_loss = train_model_2steps_temp(spherical_unet, device, dl_train, epochs=nb_epochs, \n",
    "                                               lr=learning_rate, validation_data=dl_val, \n",
    "                                               model_filename=model_filename)\n",
    "torch.save(spherical_unet.state_dict(), model_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training losses\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "del dl_train, dl_val, training_ds, validation_ds\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "testing_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_test, out_features=out_features,\n",
    "                                                  len_sqce=len_sqce, delta_t=delta_t, years=test_years, \n",
    "                                                  nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                  mean=train_mean, std=train_std, \n",
    "                                                  max_lead_time=max_lead_time)\n",
    "\n",
    "dataloader_test = DataLoader(testing_ds, batch_size=int(0.7*batch_size), shuffle=False,\n",
    "                             num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "preds = create_iterative_predictions_healpix_temp(spherical_unet, device, dataloader_test)\n",
    "preds.to_netcdf(pred_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save RMSE\n",
    "rmse = compute_rmse_healpix(preds, obs).load()\n",
    "rmse.to_netcdf(rmse_filename)\n",
    "\n",
    "# Show RMSE\n",
    "print('Z500 - 0:', rmse.z.values[0])\n",
    "print('T850 - 0:', rmse.t.values[0])\n",
    "plot_rmses(rmse, rmses_weyn, lead_time=6)\n",
    "\n",
    "del spherical_unet, preds, rmse\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
