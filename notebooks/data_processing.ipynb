{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "Download, save, visualize and load dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/\"\n",
    "resolution = \"5.625deg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "- Test: years 2017 and 2018\n",
    "- Validation: year 2016\n",
    "- Train: years 1979 to 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(DATA_DIR, train_years, val_years, test_years):\n",
    "    \n",
    "    time_slices = {'train': train_years, 'val': val_years, 'test': test_years}\n",
    "    \n",
    "    \n",
    "    zpath = DATA_DIR + '5.625deg/geopotential_500/'\n",
    "    tpath = DATA_DIR + '5.625deg/temperature_850/'\n",
    "    \n",
    "    z = xr.open_mfdataset(zpath+'/*.nc', combine='by_coords')['z'].assign_coords(level=1)\n",
    "    t = xr.open_mfdataset(tpath+'/*.nc', combine='by_coords')['t'].assign_coords(level=1)\n",
    "\n",
    "    ratio = len(z.coords['lon'])/len(z.coords['lat'])\n",
    "\n",
    "    data = xr.concat([z, t], 'level').stack(v=('lat', 'lon')).transpose('time', 'v', 'level').drop('level')\n",
    "    \n",
    "    data_paths = []\n",
    "    for set_name in ['train']:\n",
    "    \n",
    "        # Create directory\n",
    "        out_path = DATA_DIR + set_name + \"/\"\n",
    "        Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "        data_paths.append(out_path)\n",
    "        \n",
    "        # Select relevant years\n",
    "        dataset = data.sel(time=time_slices[set_name])\n",
    "\n",
    "        # Compute mean and std\n",
    "        mean = data.mean(('time', 'v')).compute()\n",
    "        std = data.std('time').mean(('v')).compute()\n",
    "        np.save(out_path + 'mean.npy', mean.values)\n",
    "        np.save(out_path + 'std.npy', std.values)\n",
    "    \n",
    "        # Save individual arrays\n",
    "        for i, array in enumerate(dataset):\n",
    "            np.save(out_path + str(i) + '.npy', array.values)\n",
    "\n",
    "def load_test_data(path, delta_t, years=slice('2017', '2018')):\n",
    "    zpath = path + '/geopotential_500'\n",
    "    tpath = path + '/temperature_850'\n",
    "    \n",
    "    z = xr.open_mfdataset(zpath+'/*.nc', combine='by_coords')['z']\n",
    "    t = xr.open_mfdataset(tpath+'/*.nc', combine='by_coords')['t']\n",
    "\n",
    "    try:\n",
    "        z = z.sel(level=500).drop('level')\n",
    "        z = z.drop('level')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        t = t.sel(level=850).drop('level')\n",
    "        t = t.drop('level')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    dataset = xr.merge([z, t], compat='override')\n",
    "\n",
    "    return dataset.sel(time=years).isel(time=slice(delta_t, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherBenchDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, delta_t, mean=None, std=None):\n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        \n",
    "        self.mean = np.load(data_path + 'mean.npy') if mean is None else mean\n",
    "        self.std = np.load(data_path + 'std.npy') if std is None else std\n",
    "        \n",
    "        '''self.transform = transforms.Compose([torch.Tensor(), \n",
    "                                              transforms.Normalize(mean=self.mean, std=self.std)])'''\n",
    "        \n",
    "        total_samples = len(os.listdir(data_path)) - 2\n",
    "        self.n_samples = total_samples - self.delta_t\n",
    "        \n",
    "        self.datafiles = [(data_path+str(id)+'.npy', data_path+str(id+delta_t)+'.npy')\n",
    "                           for id in list(range(self.n_samples))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, n_features]\n",
    "        \"\"\"\n",
    "        \n",
    "        '''X = self.transform(np.load(self.datafiles[idx]))\n",
    "        y = self.transform(np.load(self.datafiles[idx+delta_t]))'''\n",
    "        \n",
    "        X = torch.Tensor((np.load(self.datafiles[idx][0])-self.mean)/self.std)\n",
    "        y = torch.Tensor((np.load(self.datafiles[idx][1])-self.mean)/self.std)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "class WeatherBenchDataset_2D(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, delta_t, d1, d2, mean=None, std=None):\n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        \n",
    "        self.mean = np.load(data_path + 'mean.npy') if mean is None else mean\n",
    "        self.std = np.load(data_path + 'std.npy') if std is None else std\n",
    "        \n",
    "        '''self.transform = transforms.Compose([torch.Tensor(), \n",
    "                                              transforms.Normalize(mean=self.mean, std=self.std)])'''\n",
    "        \n",
    "        total_samples = len(os.listdir(data_path)) - 2\n",
    "        self.n_samples = total_samples - self.delta_t\n",
    "        \n",
    "        self.datafiles = [(data_path+str(id)+'.npy', data_path+str(id+delta_t)+'.npy')\n",
    "                           for id in list(range(self.n_samples))]\n",
    "        \n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, n_features]\n",
    "        \"\"\"\n",
    "        \n",
    "        '''X = self.transform(np.load(self.datafiles[idx]))\n",
    "        y = self.transform(np.load(self.datafiles[idx+delta_t]))'''\n",
    "        \n",
    "        X = torch.Tensor((np.load(self.datafiles[idx][0])-self.mean)/self.std).view((2, d1, d2))\n",
    "        y = torch.Tensor((np.load(self.datafiles[idx][1])-self.mean)/self.std).view((2, d1, d2))\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graphs\n",
    "\n",
    "Bandwidth = [dim1/2, dim2/2]  \n",
    "sampling = 'SOFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere.utils.laplacian_funcs import prepare_laplacian\n",
    "from deepsphere.utils.samplings import equiangular_dimension_unpack\n",
    "from pygsp.graphs.sphereequiangular import SphereEquiangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplacian(nodes, ratio, laplacian_type):\n",
    "    dim1, dim2 = equiangular_dimension_unpack(nodes, ratio)\n",
    "    \n",
    "    bw = [int(dim1/2), int(dim2/2)]\n",
    "\n",
    "    G = SphereEquiangular(bandwidth=bw, sampling=\"SOFT\")\n",
    "    G.compute_laplacian(laplacian_type)\n",
    "    laplacian = prepare_laplacian(G.L)\n",
    "    \n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The models\n",
    "\n",
    "https://github.com/ArcaniteSolutions/deepsphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from deepsphere.models.spherical_unet.encoder import SphericalChebBN2\n",
    "from deepsphere.models.spherical_unet.utils import SphericalChebBNPool\n",
    "from deepsphere.models.spherical_unet.decoder import SphericalChebBNPoolConcat, SphericalChebBNPoolCheb\n",
    "\n",
    "\n",
    "from deepsphere.layers.chebyshev import SphericalChebConv\n",
    "from deepsphere.utils.laplacian_funcs import get_equiangular_laplacians\n",
    "from deepsphere.layers.samplings.equiangular_pool_unpool import Equiangular, reformat\n",
    "from deepsphere.utils.samplings import equiangular_calculator\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiangularMaxPool2(nn.MaxPool1d):\n",
    "    \"\"\"EquiAngular Maxpooling module using MaxPool 1d from torch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratio, kernel_size, return_indices=True):\n",
    "        \"\"\"Initialization\n",
    "        Args:\n",
    "            ratio (float): ratio between latitude and longitude dimensions of the data\n",
    "        \"\"\"\n",
    "        self.ratio = ratio\n",
    "        super().__init__(kernel_size=kernel_size, return_indices=return_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"calls Maxpool1d and if desired, keeps indices of the pixels pooled to unpool them\n",
    "        Args:\n",
    "            input (:obj:`torch.tensor`): batch x pixels x features\n",
    "        Returns:\n",
    "            tuple(:obj:`torch.tensor`, list(int)): batch x pooled pixels x features and the indices of the pixels pooled\n",
    "        \"\"\"\n",
    "        x, _ = equiangular_calculator(x, self.ratio)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.return_indices:\n",
    "            x, indices = F.max_pool2d(x, self.kernel_size, return_indices=self.return_indices)\n",
    "        else:\n",
    "            x = F.max_pool2d(x, self.kernel_size)\n",
    "        x = reformat(x)\n",
    "\n",
    "        if self.return_indices:\n",
    "            output = x, indices\n",
    "        else:\n",
    "            output = x\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class EquiangularMaxUnpool2(nn.MaxUnpool1d):\n",
    "    \"\"\"Equiangular Maxunpooling using the MaxUnpool1d of pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratio, kernel_size):\n",
    "        \"\"\"Initialization\n",
    "        Args:\n",
    "            ratio (float): ratio between latitude and longitude dimensions of the data\n",
    "        \"\"\"\n",
    "        self.ratio = ratio\n",
    "        \n",
    "        super().__init__(kernel_size=(kernel_size, kernel_size))\n",
    "\n",
    "    def forward(self, x, indices):\n",
    "        \"\"\"calls MaxUnpool1d using the indices returned previously by EquiAngMaxPool\n",
    "        Args:\n",
    "            x (:obj:`torch.tensor`): batch x pixels x features\n",
    "            indices (int): indices of pixels equiangular maxpooled previously\n",
    "        Returns:\n",
    "            :obj:`torch.tensor`: batch x unpooled pixels x features\n",
    "        \"\"\"\n",
    "        x, _ = equiangular_calculator(x, self.ratio)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = F.max_unpool2d(x, indices, self.kernel_size)\n",
    "        x = reformat(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalConvNet(nn.Module):\n",
    "    \"\"\"Spherical GCNN Autoencoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nodes, ratio, depth, channels_in, channels_out, laplacian_type, kernel_size):\n",
    "        \"\"\"Initialization.\n",
    "        Args:\n",
    "            N (int): Number of pixels in the input image\n",
    "            depth (int): The depth of the UNet, which is bounded by the N and the type of pooling\n",
    "            kernel_size (int): chebychev polynomial degree\n",
    "            ratio (float): Parameter for equiangular sampling -> width/height\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.laplacian = compute_laplacian(nodes, ratio, laplacian_type)\n",
    "        \n",
    "        self.conv1 = SphericalChebConv(channels_in, 64, self.laplacian, self.kernel_size)\n",
    "        self.conv2 = SphericalChebConv(64, 64, self.laplacian, self.kernel_size)\n",
    "        self.conv3 = SphericalChebConv(64, 64, self.laplacian, self.kernel_size)\n",
    "        self.conv4 = SphericalChebConv(64, 64, self.laplacian, self.kernel_size)\n",
    "        self.conv5 = SphericalChebConv(64, channels_out, self.laplacian, self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass.\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): input to be forwarded.\n",
    "        Returns:\n",
    "            :obj:`torch.Tensor`: output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"Spherical GCNN Autoencoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels_in, channels_out, kernel_size):\n",
    "        \"\"\"Initialization.\n",
    "        Args:\n",
    "            N (int): Number of pixels in the input image\n",
    "            depth (int): The depth of the UNet, which is bounded by the N and the type of pooling\n",
    "            kernel_size (int): chebychev polynomial degree\n",
    "            ratio (float): Parameter for equiangular sampling -> width/height\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels_in, 64, self.kernel_size, padding=int((self.kernel_size - 1)/2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, self.kernel_size, padding=int((self.kernel_size - 1)/2))\n",
    "        self.conv3 = nn.Conv2d(64, 64, self.kernel_size, padding=int((self.kernel_size - 1)/2))\n",
    "        self.conv4 = nn.Conv2d(64, 64, self.kernel_size, padding=int((self.kernel_size - 1)/2))\n",
    "        self.conv5 = nn.Conv2d(64, channels_out, self.kernel_size, padding=int((self.kernel_size - 1)/2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass.\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): input to be forwarded.\n",
    "        Returns:\n",
    "            :obj:`torch.Tensor`: output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr, device, train_generator, val_generator, patience, out_filename):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    min_val_loss = float(\"inf\")\n",
    "    epoch_no_improve = 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (batch, labels) in enumerate(train_generator):\n",
    "            # Transfer to GPU\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            \n",
    "            # Model\n",
    "            output = model(batch)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            train_loss = train_loss + loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss = train_loss / len(train_generator)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for batch, labels in val_generator:\n",
    "                # Transfer to GPU\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                \n",
    "                output = model(batch)\n",
    "\n",
    "                val_loss = val_loss + criterion(output, labels).item()\n",
    "                \n",
    "        val_loss = val_loss/len(train_generator)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=n_epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "                \n",
    "        # Check for early stopping\n",
    "        if val_loss < min_val_loss:\n",
    "            epoch_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "        else:\n",
    "            epoch_no_improve += 1\n",
    "\n",
    "        if epoch_no_improve == patience:\n",
    "            print('Epoch {e:3d}: early stopping'.format(e=epoch+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_device(model, ids=None):\n",
    "    \"\"\"Initialize device based on cpu/gpu and number of gpu\n",
    "    Args:\n",
    "        device (str): cpu or gpu\n",
    "        ids (list of int or str): list of gpus that should be used\n",
    "        unet (torch.Module): the model to place on the device(s)\n",
    "    Raises:\n",
    "        Exception: There is an error in configuring the cpu or gpu\n",
    "    Returns:\n",
    "        torch.Module, torch.device: the model placed on device, the device\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        if ids is None:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = model.to(device)\n",
    "            model = nn.DataParallel(model)\n",
    "        elif len(ids) == 1:\n",
    "            device = torch.device(\"cuda:{}\".format(ids[0]))\n",
    "            model = model.to(device)\n",
    "        else:\n",
    "            device = torch.device(\"cuda:{}\".format(ids[0]))\n",
    "            model = model.to(device)\n",
    "            model = nn.DataParallel(model, device_ids=[int(i) for i in ids])\n",
    "        #cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, valid_data):\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    \n",
    "    fcs = []\n",
    "    outputs = []\n",
    "    for i, (sample, label) in enumerate(loader):\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        outputs.append(model(sample).detach().cpu().clone().numpy().squeeze(0))\n",
    "    \n",
    "    # Unnormalize and reshape\n",
    "    outputs = np.array(outputs)\n",
    "    outputs = outputs * dataset.std + dataset.mean\n",
    "    outputs = outputs.reshape((outputs.shape[0], valid.dims['lat'], valid.dims['lon'], outputs.shape[2]))\n",
    "        \n",
    "    for var_idx, var in enumerate(valid_data.data_vars):\n",
    "        fcs.append(xr.DataArray(outputs[:, :, :, var_idx],\n",
    "                                dims=['time', 'lat', 'lon'],\n",
    "                                coords={'time': valid_data.time, 'lat': valid_data.lat, 'lon': valid_data.lon},\n",
    "                                name=var))\n",
    "    \n",
    "    return xr.merge(fcs)\n",
    "\n",
    "def predict_2D(model, dataset, valid_data):\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    \n",
    "    fcs = []\n",
    "    outputs = []\n",
    "    for i, (sample, label) in enumerate(loader):\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        output = model(sample).detach().cpu().clone().numpy().squeeze(0).reshape((32, 64, 2))\n",
    "        outputs.append(output)\n",
    "    \n",
    "    # Unnormalize\n",
    "    outputs = np.array(outputs)\n",
    "    outputs = outputs * dataset.std + dataset.mean\n",
    "        \n",
    "    for var_idx, var in enumerate(valid_data.data_vars):\n",
    "        fcs.append(xr.DataArray(outputs[:, :, :, var_idx],\n",
    "                                dims=['time', 'lat', 'lon'],\n",
    "                                coords={'time': valid_data.time, 'lat': valid_data.lat, 'lon': valid_data.lon},\n",
    "                                name=var))\n",
    "    \n",
    "    return xr.merge(fcs)\n",
    "\n",
    "def compute_weighted_rmse(da_fc, da_true, mean_dims=xr.ALL_DIMS):\n",
    "    \"\"\"\n",
    "    Compute the RMSE with latitude weighting from two xr.DataArrays.\n",
    "    Args:\n",
    "        da_fc (xr.DataArray): Forecast. Time coordinate must be validation time.\n",
    "        da_true (xr.DataArray): Truth.\n",
    "    Returns:x\n",
    "        rmse: Latitude weighted root mean squared error\n",
    "    \"\"\"\n",
    "    error = da_fc - da_true\n",
    "    weights_lat = np.cos(np.deg2rad(error.lat))\n",
    "    weights_lat /= weights_lat.mean()\n",
    "    rmse = np.sqrt(((error)**2 * weights_lat).mean(mean_dims))\n",
    "    if type(rmse) is xr.Dataset:\n",
    "        rmse = rmse.rename({v: v + '_rmse' for v in rmse})\n",
    "    else: # DataArray\n",
    "        rmse.name = error.name + '_rmse' if not error.name is None else 'rmse'\n",
    "    return rmse\n",
    "\n",
    "def compute_rmse(da_fc, da_true, mean_dims=xr.ALL_DIMS):\n",
    "    \"\"\"\n",
    "    Compute the RMSE with latitude weighting from two xr.DataArrays.\n",
    "    Args:\n",
    "        da_fc (xr.DataArray): Forecast. Time coordinate must be validation time.\n",
    "        da_true (xr.DataArray): Truth.\n",
    "    Returns:\n",
    "        rmse: Latitude weighted root mean squared error\n",
    "    \"\"\"\n",
    "    error = da_fc - da_true\n",
    "    rmse = np.sqrt(((error)**2).mean(mean_dims))\n",
    "    if type(rmse) is xr.Dataset:\n",
    "        rmse = rmse.rename({v: v + '_rmse' for v in rmse})\n",
    "    else: # DataArray\n",
    "        rmse.name = error.name + '_rmse' if not error.name is None else 'rmse'\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = DATA_DIR + \"train/\"\n",
    "val_path = DATA_DIR + \"val/\"\n",
    "test_path = DATA_DIR + \"test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 day prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spherical convolution + combinatorial Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 3*24  # 3 days\n",
    "ratio = 64/32   # lon/lat\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4  # we doubled the learning rate as we doubled the batch size\n",
    "n_epochs = 100\n",
    "\n",
    "# Data\n",
    "training_set = WeatherBenchDataset(train_path, lead_time)\n",
    "validation_set = WeatherBenchDataset(val_path, lead_time, training_set.mean, training_set.std)\n",
    "dataloader_train = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "dataloader_validation = DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "\n",
    "N = len(training_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model - CONVNET\n",
    "convnet = SphericalConvNet(nodes=N, ratio=ratio, depth=4, channels_in=2, channels_out=2, laplacian_type=\"combinatorial\", \n",
    "                           kernel_size=5)\n",
    "\n",
    "convnet, device = init_device(model=convnet, ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/100  - loss: 0.692  - val_loss: 0.017  - time: 408.169278\n",
      "Epoch:   2/100  - loss: 0.613  - val_loss: 0.017  - time: 409.275861\n",
      "Epoch:   3/100  - loss: 0.607  - val_loss: 0.017  - time: 408.563647\n",
      "Epoch:   4/100  - loss: 0.602  - val_loss: 0.016  - time: 409.316553\n",
      "Epoch:   5/100  - loss: 0.596  - val_loss: 0.016  - time: 410.081473\n",
      "Epoch:   6/100  - loss: 0.592  - val_loss: 0.016  - time: 409.226164\n",
      "Epoch:   7/100  - loss: 0.588  - val_loss: 0.016  - time: 409.561004\n",
      "Epoch:   8/100  - loss: 0.586  - val_loss: 0.016  - time: 409.839350\n",
      "Epoch:   9/100  - loss: 0.583  - val_loss: 0.016  - time: 410.048461\n",
      "Epoch:  10/100  - loss: 0.582  - val_loss: 0.016  - time: 410.152391\n",
      "Epoch:  11/100  - loss: 0.580  - val_loss: 0.016  - time: 410.555949\n",
      "Epoch:  12/100  - loss: 0.579  - val_loss: 0.016  - time: 410.275508\n",
      "Epoch:  13/100  - loss: 0.578  - val_loss: 0.016  - time: 410.017483\n",
      "Epoch:  14/100  - loss: 0.577  - val_loss: 0.016  - time: 410.114794\n",
      "Epoch:  15/100  - loss: 0.576  - val_loss: 0.016  - time: 410.040204\n",
      "Epoch:  16/100  - loss: 0.575  - val_loss: 0.016  - time: 410.948182\n",
      "Epoch:  17/100  - loss: 0.574  - val_loss: 0.016  - time: 410.707019\n",
      "Epoch:  18/100  - loss: 0.573  - val_loss: 0.016  - time: 410.176328\n",
      "Epoch:  19/100  - loss: 0.572  - val_loss: 0.016  - time: 410.415306\n",
      "Epoch:  20/100  - loss: 0.572  - val_loss: 0.016  - time: 409.885992\n",
      "Epoch:  21/100  - loss: 0.571  - val_loss: 0.016  - time: 411.117200\n",
      "Epoch:  22/100  - loss: 0.571  - val_loss: 0.016  - time: 410.993721\n",
      "Epoch:  23/100  - loss: 0.570  - val_loss: 0.016  - time: 410.926826\n",
      "Epoch:  24/100  - loss: 0.569  - val_loss: 0.016  - time: 410.300638\n",
      "Epoch:  25/100  - loss: 0.569  - val_loss: 0.016  - time: 410.352921\n",
      "Epoch:  26/100  - loss: 0.569  - val_loss: 0.016  - time: 410.467290\n",
      "Epoch:  27/100  - loss: 0.568  - val_loss: 0.015  - time: 410.315911\n",
      "Epoch:  28/100  - loss: 0.568  - val_loss: 0.016  - time: 410.732843\n",
      "Epoch:  29/100  - loss: 0.567  - val_loss: 0.016  - time: 411.494783\n",
      "Epoch:  30/100  - loss: 0.567  - val_loss: 0.015  - time: 410.424790\n",
      "Epoch:  31/100  - loss: 0.567  - val_loss: 0.015  - time: 410.065377\n",
      "Epoch:  32/100  - loss: 0.566  - val_loss: 0.015  - time: 410.030061\n",
      "Epoch:  33/100  - loss: 0.566  - val_loss: 0.015  - time: 410.966367\n",
      "Epoch:  34/100  - loss: 0.565  - val_loss: 0.016  - time: 411.179562\n",
      "Epoch:  35/100  - loss: 0.565  - val_loss: 0.015  - time: 410.631029\n",
      "Epoch  35: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_model(convnet, learning_rate, device, dataloader_train, dataloader_validation, patience=3)\n",
    "torch.save(convnet_norm_5d.state_dict(), DATA_DIR + 'predictions/models/spherical_3d.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeatherBench CNN:  \n",
    "**3 days** \n",
    "\n",
    " Z500: 626   \n",
    "  T850: 2.87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Coordinates:\n",
      "    level    int32 500\n",
      "Data variables:\n",
      "    z_rmse   float64 782.9\n",
      "    t_rmse   float64 3.514\n"
     ]
    }
   ],
   "source": [
    "testing_set = WeatherBenchDataset(test_path, lead_time, training_set.mean, training_set.std)\n",
    "\n",
    "valid = load_test_data(DATA_DIR + resolution, lead_time)\n",
    "pred = predict(convnet, testing_set, valid)\n",
    "\n",
    "print(compute_weighted_rmse(pred, valid).load())\n",
    "pred.to_netcdf(DATA_DIR + 'predictions/cnn_3d.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spherical convolution, normalized Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/100  - loss: 0.560  - val_loss: 0.01451  - time: 405.696800\n",
      "Epoch:   2/100  - loss: 0.524  - val_loss: 0.01419  - time: 405.163059\n",
      "Epoch:   3/100  - loss: 0.515  - val_loss: 0.01410  - time: 405.342869\n",
      "Epoch:   4/100  - loss: 0.510  - val_loss: 0.01390  - time: 405.283878\n",
      "Epoch:   5/100  - loss: 0.505  - val_loss: 0.01375  - time: 404.655941\n",
      "Epoch:   6/100  - loss: 0.501  - val_loss: 0.01369  - time: 405.263626\n",
      "Epoch:   7/100  - loss: 0.498  - val_loss: 0.01361  - time: 406.653202\n",
      "Epoch:   8/100  - loss: 0.496  - val_loss: 0.01354  - time: 405.700488\n",
      "Epoch:   9/100  - loss: 0.493  - val_loss: 0.01362  - time: 405.799430\n",
      "Epoch:  10/100  - loss: 0.491  - val_loss: 0.01340  - time: 405.161045\n",
      "Epoch:  11/100  - loss: 0.489  - val_loss: 0.01337  - time: 405.241851\n",
      "Epoch:  12/100  - loss: 0.487  - val_loss: 0.01330  - time: 405.320623\n",
      "Epoch:  13/100  - loss: 0.485  - val_loss: 0.01321  - time: 405.607914\n",
      "Epoch:  14/100  - loss: 0.483  - val_loss: 0.01318  - time: 405.465594\n",
      "Epoch:  15/100  - loss: 0.481  - val_loss: 0.01321  - time: 406.205444\n",
      "Epoch:  16/100  - loss: 0.480  - val_loss: 0.01318  - time: 406.517383\n",
      "Epoch:  17/100  - loss: 0.478  - val_loss: 0.01313  - time: 405.790856\n",
      "Epoch:  18/100  - loss: 0.477  - val_loss: 0.01302  - time: 405.359039\n",
      "Epoch:  19/100  - loss: 0.475  - val_loss: 0.01297  - time: 406.126354\n",
      "Epoch:  20/100  - loss: 0.474  - val_loss: 0.01296  - time: 405.605473\n",
      "Epoch:  21/100  - loss: 0.473  - val_loss: 0.01293  - time: 406.440865\n",
      "Epoch:  22/100  - loss: 0.472  - val_loss: 0.01293  - time: 407.272287\n",
      "Epoch:  23/100  - loss: 0.471  - val_loss: 0.01286  - time: 406.483943\n",
      "Epoch:  24/100  - loss: 0.470  - val_loss: 0.01295  - time: 405.206985\n",
      "Epoch:  25/100  - loss: 0.469  - val_loss: 0.01282  - time: 405.743396\n",
      "Epoch:  26/100  - loss: 0.468  - val_loss: 0.01279  - time: 405.715002\n",
      "Epoch:  27/100  - loss: 0.467  - val_loss: 0.01281  - time: 406.278301\n",
      "Epoch:  28/100  - loss: 0.466  - val_loss: 0.01278  - time: 405.474887\n",
      "Epoch:  29/100  - loss: 0.465  - val_loss: 0.01283  - time: 405.823300\n",
      "Epoch:  30/100  - loss: 0.465  - val_loss: 0.01284  - time: 405.451282\n",
      "Epoch:  31/100  - loss: 0.464  - val_loss: 0.01273  - time: 406.121114\n",
      "Epoch:  32/100  - loss: 0.463  - val_loss: 0.01272  - time: 405.690970\n",
      "Epoch:  33/100  - loss: 0.462  - val_loss: 0.01268  - time: 407.265147\n",
      "Epoch:  34/100  - loss: 0.462  - val_loss: 0.01269  - time: 406.172907\n",
      "Epoch:  35/100  - loss: 0.461  - val_loss: 0.01263  - time: 406.355664\n",
      "Epoch:  36/100  - loss: 0.460  - val_loss: 0.01264  - time: 405.670581\n",
      "Epoch:  37/100  - loss: 0.460  - val_loss: 0.01262  - time: 405.361565\n",
      "Epoch:  38/100  - loss: 0.459  - val_loss: 0.01266  - time: 405.687279\n",
      "Epoch:  39/100  - loss: 0.459  - val_loss: 0.01260  - time: 406.454003\n",
      "Epoch:  40/100  - loss: 0.458  - val_loss: 0.01261  - time: 405.574922\n",
      "Epoch:  41/100  - loss: 0.458  - val_loss: 0.01256  - time: 406.127026\n",
      "Epoch:  42/100  - loss: 0.457  - val_loss: 0.01256  - time: 406.002810\n",
      "Epoch:  43/100  - loss: 0.457  - val_loss: 0.01255  - time: 405.817411\n",
      "Epoch:  44/100  - loss: 0.456  - val_loss: 0.01255  - time: 405.743829\n",
      "Epoch:  45/100  - loss: 0.456  - val_loss: 0.01255  - time: 406.478031\n",
      "Epoch:  46/100  - loss: 0.455  - val_loss: 0.01247  - time: 405.987170\n",
      "Epoch:  47/100  - loss: 0.455  - val_loss: 0.01249  - time: 405.905416\n",
      "Epoch:  48/100  - loss: 0.454  - val_loss: 0.01254  - time: 405.724677\n",
      "Epoch:  49/100  - loss: 0.454  - val_loss: 0.01247  - time: 405.832545\n",
      "Epoch  49: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model - CONVNET\n",
    "convnet_norm = SphericalConvNet(nodes=N, ratio=ratio, depth=4, channels_in=2, channels_out=2, \n",
    "                                laplacian_type=\"normalized\", kernel_size=5)\n",
    "\n",
    "convnet_norm, device = init_device(model=convnet_norm, ids=[0, 1])\n",
    "\n",
    "train_model(convnet_norm, learning_rate, device, dataloader_train, dataloader_validation, patience=3, \n",
    "            out_filename='spherical_norm')\n",
    "torch.save(convnet_norm_5d.state_dict(), DATA_DIR + 'predictions/models/spherical_norm_3d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Coordinates:\n",
      "    level    int32 500\n",
      "Data variables:\n",
      "    z_rmse   float64 684.8\n",
      "    t_rmse   float64 3.136\n"
     ]
    }
   ],
   "source": [
    "testing_set = WeatherBenchDataset(test_path, lead_time, training_set.mean, training_set.std)\n",
    "\n",
    "valid = load_test_data(DATA_DIR + resolution, lead_time)\n",
    "pred_norm = predict(convnet_norm, testing_set, valid)\n",
    "\n",
    "print(compute_weighted_rmse(pred_norm, valid).load())\n",
    "pred_norm.to_netcdf(DATA_DIR + 'predictions/spherical_norm_cnn_3d.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Conv2D (to check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 32\n",
    "d2 = 64\n",
    "\n",
    "# Data\n",
    "training_set2 = WeatherBenchDataset_2D(train_path, lead_time, d1, d2)\n",
    "validation_set2 = WeatherBenchDataset_2D(val_path, lead_time, d1, d2, training_set.mean, training_set.std)\n",
    "dataloader_train2 = DataLoader(training_set2, batch_size=batch_size, shuffle=True, num_workers=18)\n",
    "dataloader_validation2 = DataLoader(validation_set2, batch_size=batch_size, shuffle=False, num_workers=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/100  - loss: 0.592  - val_loss: 0.015  - time: 119.149400\n",
      "Epoch:   2/100  - loss: 0.516  - val_loss: 0.014  - time: 121.841047\n",
      "Epoch:   3/100  - loss: 0.502  - val_loss: 0.014  - time: 122.630191\n",
      "Epoch:   4/100  - loss: 0.493  - val_loss: 0.014  - time: 122.143582\n",
      "Epoch:   5/100  - loss: 0.486  - val_loss: 0.013  - time: 122.023354\n",
      "Epoch:   6/100  - loss: 0.480  - val_loss: 0.013  - time: 121.889789\n",
      "Epoch:   7/100  - loss: 0.475  - val_loss: 0.013  - time: 122.443707\n",
      "Epoch:   8/100  - loss: 0.471  - val_loss: 0.013  - time: 121.194716\n",
      "Epoch:   9/100  - loss: 0.468  - val_loss: 0.013  - time: 121.848344\n",
      "Epoch:  10/100  - loss: 0.464  - val_loss: 0.013  - time: 122.423473\n",
      "Epoch:  11/100  - loss: 0.462  - val_loss: 0.013  - time: 122.081895\n",
      "Epoch:  12/100  - loss: 0.459  - val_loss: 0.013  - time: 122.171533\n",
      "Epoch:  13/100  - loss: 0.457  - val_loss: 0.013  - time: 121.366228\n",
      "Epoch:  14/100  - loss: 0.455  - val_loss: 0.013  - time: 121.735054\n",
      "Epoch:  15/100  - loss: 0.453  - val_loss: 0.013  - time: 121.267254\n",
      "Epoch:  16/100  - loss: 0.451  - val_loss: 0.013  - time: 121.773134\n",
      "Epoch:  17/100  - loss: 0.449  - val_loss: 0.013  - time: 121.337604\n",
      "Epoch:  18/100  - loss: 0.448  - val_loss: 0.013  - time: 121.804023\n",
      "Epoch:  19/100  - loss: 0.446  - val_loss: 0.013  - time: 121.271815\n",
      "Epoch:  20/100  - loss: 0.445  - val_loss: 0.013  - time: 121.275958\n",
      "Epoch:  21/100  - loss: 0.443  - val_loss: 0.013  - time: 121.214001\n",
      "Epoch:  22/100  - loss: 0.442  - val_loss: 0.013  - time: 121.391840\n",
      "Epoch:  23/100  - loss: 0.441  - val_loss: 0.013  - time: 121.409501\n",
      "Epoch  23: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "cnn = ConvNet(channels_in=2, channels_out=2, kernel_size=5)\n",
    "cnn, device = init_device(model=cnn, ids=[0, 1])\n",
    "\n",
    "train_model(cnn, learning_rate, device, dataloader_train2, dataloader_validation2, patience=3, 'cnn_model')\n",
    "torch.save(convnet_norm_5d.state_dict(), DATA_DIR + 'predictions/models/cnn_3d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Coordinates:\n",
      "    level    int32 500\n",
      "Data variables:\n",
      "    z_rmse   float64 704.5\n",
      "    t_rmse   float64 3.158\n"
     ]
    }
   ],
   "source": [
    "testing_set2 = WeatherBenchDataset2(test_path, lead_time, d1, d2, training_set2.mean, training_set2.std)\n",
    "\n",
    "valid = load_test_data(DATA_DIR + resolution, lead_time)\n",
    "pred2 = predict_2D(cnn, testing_set2, valid)\n",
    "\n",
    "print(compute_weighted_rmse(pred2, valid).load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_bias(da_fc, da_true, mean_dims=xr.ALL_DIMS):\n",
    "    error = da_fc - da_true\n",
    "    rbias = error.mean(mean_dims) / da_true.mean(mean_dims)\n",
    "    if type(rbias) is xr.Dataset:\n",
    "        rbias = rbias.rename({v: v + '_rbias' for v in rbias})\n",
    "    else: # DataArray\n",
    "        rbias.name = error.name + '_rbias' if not error.name is None else 'rbias'\n",
    "    return rbias\n",
    "\n",
    "\n",
    "def relative_std(da_fc, da_true, mean_dims=xr.ALL_DIMS):\n",
    "    error = da_fc - da_true\n",
    "    rsd = error.std(mean_dims) / da_true.std(mean_dims)\n",
    "    if type(rsd) is xr.Dataset:\n",
    "        rsd = rsd.rename({v: v + '_rsd' for v in rsd})\n",
    "    else: # DataArray\n",
    "        rsd.name = error.name + '_rsd' if not error.name is None else 'rsd'\n",
    "    return rsd\n",
    "\n",
    "def compute_weighted_rmse_graph(da_fc, da_true):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Coordinates:\n",
      "    level    int32 500\n",
      "Data variables:\n",
      "    z_rbias  float32 -0.00021429219\n",
      "    t_rbias  float32 -0.00013827773\n"
     ]
    }
   ],
   "source": [
    "print(relative_bias(pred_norm, valid).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Coordinates:\n",
      "    level    int32 500\n",
      "Data variables:\n",
      "    z_rsd    float32 0.23691319\n",
      "    t_rsd    float32 0.23131287\n"
     ]
    }
   ],
   "source": [
    "print(relative_std(pred_norm, valid).load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is slightly underestimated but probably negligible. This is to be expected since we're minimizing the MSE. \n",
    "\n",
    "std is VERY underestimated, also because of the MSE evaluation probably. \n",
    "\n",
    "=> **these results should get much better with another loss function already**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 day prediction\n",
    "\n",
    "### Spherical, normalized Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_5d = 5*24  # 5 days\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4  # we doubled the learning rate as we doubled the batch size\n",
    "n_epochs = 100\n",
    "\n",
    "# Data\n",
    "training_set_5d = WeatherBenchDataset(train_path, lead_time_5d)\n",
    "validation_set_5d = WeatherBenchDataset(val_path, lead_time_5d, training_set_5d.mean, training_set_5d.std)\n",
    "dataloader_train_5d = DataLoader(training_set_5d, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "dataloader_validation_5d = DataLoader(validation_set_5d, batch_size=batch_size, shuffle=False, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/100  - loss: 0.719  - val_loss: 0.01759  - time: 407.138790\n",
      "Epoch:   2/100  - loss: 0.648  - val_loss: 0.01725  - time: 405.503018\n",
      "Epoch:   3/100  - loss: 0.639  - val_loss: 0.01710  - time: 405.702443\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-f0cecd767832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m train_model(convnet_norm_5d, learning_rate, device, dataloader_train_5d, dataloader_validation_5d, patience=3, \n\u001b[0;32m----> 8\u001b[0;31m             out_filename='spherical_norm')\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvnet_norm_5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'predictions/models/convnet_norm_5d.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-8cab16ffd4b4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, lr, device, train_generator, val_generator, patience, out_filename)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather_modelling/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather_modelling/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/weather_modelling/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model - CONVNET\n",
    "convnet_norm_5d = SphericalConvNet(nodes=N, ratio=ratio, depth=4, channels_in=2, channels_out=2, \n",
    "                                   laplacian_type=\"normalized\", kernel_size=5)\n",
    "\n",
    "convnet_norm_5d, device = init_device(model=convnet_norm_5d, ids=[0, 1])\n",
    "\n",
    "train_model(convnet_norm_5d, learning_rate, device, dataloader_train_5d, dataloader_validation_5d, patience=3, \n",
    "            out_filename='spherical_norm')\n",
    "\n",
    "torch.save(convnet_norm_5d.state_dict(), DATA_DIR + 'predictions/models/spherical_norm_5d.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeatherBench CNN:  \n",
    "**5 days** \n",
    "\n",
    " Z500: 757   \n",
    " T850: 3.37\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing_set_5d = WeatherBenchDataset(test_path, lead_time_5d, training_set_5d.mean, training_set_5d.std)\n",
    "\n",
    "valid_5d = load_test_data(DATA_DIR + resolution, lead_time_5d)\n",
    "pred_norm_5d = predict(convnet_norm_5d, testing_set_5d, valid_5d)\n",
    "\n",
    "print(compute_weighted_rmse(pred_norm_5d, valid_5d).load())\n",
    "\n",
    "pred_norm_5d.to_netcdf(DATA_DIR + 'predictions/spherical_norm_cnn_5d.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "blob = compute_laplacian(N, ratio, \"normalized\").to_dense().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa33447c610>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(blob, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-87.1875, -81.5625, -75.9375, -70.3125, -64.6875, -59.0625,\n",
       "       -53.4375, -47.8125, -42.1875, -36.5625, -30.9375, -25.3125,\n",
       "       -19.6875, -14.0625,  -8.4375,  -2.8125,   2.8125,   8.4375,\n",
       "        14.0625,  19.6875,  25.3125,  30.9375,  36.5625,  42.1875,\n",
       "        47.8125,  53.4375,  59.0625,  64.6875,  70.3125,  75.9375,\n",
       "        81.5625,  87.1875])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_norm.lat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,   5.625,  11.25 ,  16.875,  22.5  ,  28.125,  33.75 ,\n",
       "        39.375,  45.   ,  50.625,  56.25 ,  61.875,  67.5  ,  73.125,\n",
       "        78.75 ,  84.375,  90.   ,  95.625, 101.25 , 106.875, 112.5  ,\n",
       "       118.125, 123.75 , 129.375, 135.   , 140.625, 146.25 , 151.875,\n",
       "       157.5  , 163.125, 168.75 , 174.375, 180.   , 185.625, 191.25 ,\n",
       "       196.875, 202.5  , 208.125, 213.75 , 219.375, 225.   , 230.625,\n",
       "       236.25 , 241.875, 247.5  , 253.125, 258.75 , 264.375, 270.   ,\n",
       "       275.625, 281.25 , 286.875, 292.5  , 298.125, 303.75 , 309.375,\n",
       "       315.   , 320.625, 326.25 , 331.875, 337.5  , 343.125, 348.75 ,\n",
       "       354.375])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_norm.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lon_lat_to_cartesian(lon, lat, R = 1):\n",
    "    \"\"\"\n",
    "    calculates lon, lat coordinates of a point on a sphere with\n",
    "    radius R\n",
    "    \"\"\"\n",
    "    lon, lat = np.meshgrid(lon, lat)\n",
    "    \n",
    "    lon_r = np.radians(lon)\n",
    "    lat_r = np.radians(lat)\n",
    "\n",
    "    x =  R * np.cos(lat_r) * np.cos(lon_r)\n",
    "    y = R * np.cos(lat_r) * np.sin(lon_r)\n",
    "    z = R * np.sin(lat_r)\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = lon_lat_to_cartesian(pred_norm.lon.values, pred_norm.lat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.99879546, -0.99879546, -0.99879546, ..., -0.99879546,\n",
       "         -0.99879546, -0.99879546],\n",
       "        [-0.98917651, -0.98917651, -0.98917651, ..., -0.98917651,\n",
       "         -0.98917651, -0.98917651],\n",
       "        [-0.97003125, -0.97003125, -0.97003125, ..., -0.97003125,\n",
       "         -0.97003125, -0.97003125],\n",
       "        ...,\n",
       "        [ 0.97003125,  0.97003125,  0.97003125, ...,  0.97003125,\n",
       "          0.97003125,  0.97003125],\n",
       "        [ 0.98917651,  0.98917651,  0.98917651, ...,  0.98917651,\n",
       "          0.98917651,  0.98917651],\n",
       "        [ 0.99879546,  0.99879546,  0.99879546, ...,  0.99879546,\n",
       "          0.99879546,  0.99879546]],\n",
       "\n",
       "       [[ 0.        ,  0.00480947,  0.00957263, ..., -0.01424359,\n",
       "         -0.00957263, -0.00480947],\n",
       "        [ 0.        ,  0.0143821 ,  0.0286257 , ..., -0.04259361,\n",
       "         -0.0286257 , -0.0143821 ],\n",
       "        [ 0.        ,  0.02381622,  0.04740308, ..., -0.07053342,\n",
       "         -0.04740308, -0.02381622],\n",
       "        ...,\n",
       "        [ 0.        ,  0.02381622,  0.04740308, ..., -0.07053342,\n",
       "         -0.04740308, -0.02381622],\n",
       "        [ 0.        ,  0.0143821 ,  0.0286257 , ..., -0.04259361,\n",
       "         -0.0286257 , -0.0143821 ],\n",
       "        [ 0.        ,  0.00480947,  0.00957263, ..., -0.01424359,\n",
       "         -0.00957263, -0.00480947]],\n",
       "\n",
       "       [[ 0.04906767,  0.0488314 ,  0.04812485, ...,  0.04695484,\n",
       "          0.04812485,  0.0488314 ],\n",
       "        [ 0.14673047,  0.14602393,  0.14391109, ...,  0.14041231,\n",
       "          0.14391109,  0.14602393],\n",
       "        [ 0.24298018,  0.24181016,  0.23831138, ...,  0.23251753,\n",
       "          0.23831138,  0.24181016],\n",
       "        ...,\n",
       "        [ 0.24298018,  0.24181016,  0.23831138, ...,  0.23251753,\n",
       "          0.23831138,  0.24181016],\n",
       "        [ 0.14673047,  0.14602393,  0.14391109, ...,  0.14041231,\n",
       "          0.14391109,  0.14602393],\n",
       "        [ 0.04906767,  0.0488314 ,  0.04812485, ...,  0.04695484,\n",
       "          0.04812485,  0.0488314 ]]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
