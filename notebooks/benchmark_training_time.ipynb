{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check influence of different parameters in performance. \n",
    "\n",
    "Check influence of:\n",
    "- specifying different chunk sizes and chunking along different dimensions\n",
    "- use already standardized data --> does it save memory?\n",
    "- use ``` .persist()``` to load data in a distributed way and speed up reading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_contants = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import healpy as hp\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.utils import train_model_2steps, init_device\n",
    "from modules.data import WeatherBenchDatasetXarrayHealpix\n",
    "from modules.healpix_models import UNetSphericalHealpix\n",
    "from modules.test import create_iterative_predictions_healpix\n",
    "from modules.test import compute_rmse_healpix\n",
    "from modules.plotting import plot_rmses\n",
    "\n",
    "datadir = \"../data/healpix/\"\n",
    "input_dir = datadir + \"5.625deg_nearest/\"\n",
    "model_save_path = datadir + \"models/\"\n",
    "pred_save_path = datadir + \"predictions/\"\n",
    "\n",
    "train_years = ('1979', '2012')\n",
    "val_years = ('2013', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "nodes = 12*16*16\n",
    "max_lead_time = 5*24\n",
    "lead_time = 6\n",
    "out_features = 2\n",
    "nb_timesteps = 2\n",
    "len_sqce = 2\n",
    "#Â define time resolution\n",
    "delta_t = 6\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,4\"\n",
    "gpu = [0,1]\n",
    "num_workers = 10\n",
    "pin_memory = True\n",
    "batch_size = 95\n",
    "\n",
    "nb_epochs = 10\n",
    "learning_rate = 8e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import WeatherBenchDatasetIterative\n",
    "class WeatherBenchDatasetXarrayHealpixTemp(Dataset):\n",
    "    \n",
    "    \"\"\" Dataset used for graph models (1D), where data is loaded from stored numpy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray Dataset\n",
    "        Dataset containing the input data\n",
    "    out_features : int\n",
    "        Number of output features\n",
    "    delta_t : int\n",
    "        Temporal spacing between samples in temporal sequence (in hours)\n",
    "    len_sqce : int\n",
    "        Length of the input and output (predicted) sequences\n",
    "    years : tuple(str)\n",
    "        Years used to split the data\n",
    "    nodes : float\n",
    "        Number of nodes each sample has\n",
    "    max_lead_time : int\n",
    "        Maximum lead time (in case of iterative predictions) in hours\n",
    "    load : bool\n",
    "        If true, load dataset to RAM\n",
    "    mean : np.ndarray of shape 2\n",
    "        Mean to use for data normalization. If None, mean is computed from data\n",
    "    std : np.ndarray of shape 2\n",
    "        std to use for data normalization. If None, mean is computed from data\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, ds, out_features, delta_t, len_sqce, years, nodes, nb_timesteps, \n",
    "                 max_lead_time=None, load=False, mean=None, std=None, standardize=True):\n",
    "        \n",
    "        \n",
    "        self.delta_t = delta_t\n",
    "        self.len_sqce = len_sqce\n",
    "        self.years = years\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.out_features = out_features\n",
    "        self.max_lead_time = max_lead_time\n",
    "        self.nb_timesteps = nb_timesteps\n",
    "        \n",
    "        self.data = ds.to_array(dim='level', name='Dataset').transpose('time', 'node', 'level')\n",
    "        \n",
    "        self.in_features = self.data.shape[-1]\n",
    "        \n",
    "        if standardize:\n",
    "            self.mean = self.data.mean(('time', 'node')).compute() if mean is None else mean\n",
    "            self.std = self.data.std(('time', 'node')).compute() if std is None else std\n",
    "        \n",
    "        eps = 0.001 #add to std to avoid division by 0\n",
    "        \n",
    "        # Count total number of samples\n",
    "        total_samples = self.data.shape[0]        \n",
    "        \n",
    "        if max_lead_time is None:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t\n",
    "        else:\n",
    "            self.n_samples = total_samples - (len_sqce+1) * delta_t - max_lead_time\n",
    "        \n",
    "        # Normalize\n",
    "        if standardize:\n",
    "            self.data = (self.data - self.mean.to_array(dim='level')) / (self.std.to_array(dim='level') + eps)\n",
    "        \n",
    "        self.data.persist()\n",
    "        self.idxs = np.array(range(self.n_samples))\n",
    "        \n",
    "        if load:\n",
    "            print('Loading data to RAM...')\n",
    "            self.data.load()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns sample and label corresponding to an index as torch.Tensor objects\n",
    "            The return tensor shapes are (for the sample and the label): [n_vertex, len_sqce, n_features]\n",
    "            \n",
    "        \"\"\"\n",
    "        idx_data = idx#self.idxs[idx]\n",
    "        #1,0,2\n",
    "        \n",
    "        #batch[0] --> (batch_size, num_nodes, n_features*len_sq)\n",
    "        idx_full = np.concatenate([idx_data+delta_t,  idx_data + delta_t * len_sqce, idx_data + delta_t * (len_sqce+1)])\n",
    "        dat = self.data.isel(time=idx_full).values\n",
    "        \n",
    "        \n",
    "        X = (\n",
    "            torch.tensor(dat[:len(idx),:,:] , \\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1),\n",
    "        )\n",
    "        \n",
    "        y = (torch.tensor(dat[len(idx):len(idx)*2,:,:],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1),\\\n",
    "             torch.tensor(dat[len(idx)*2:,:,:out_features],\\\n",
    "                         dtype=torch.float).reshape(len(idx), self.nodes, -1)\n",
    "        \n",
    "        )\n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description = \"no_const\"\n",
    "description = \"all_const_hd5\"\n",
    "\n",
    "model_filename = model_save_path + \"spherical_unet_\" + description + \".h5\"\n",
    "pred_filename = pred_save_path + \"spherical_unet_\" + description + \".nc\"\n",
    "rmse_filename = datadir + 'metrics/rmse_' + description + '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #old: in_channels=in_features*len_sqce\n",
    "spherical_unet = UNetSphericalHealpix(N=nodes, in_channels=7, out_channels=2, \n",
    "                                      kernel_size=3)\n",
    "spherical_unet, device = init_device(spherical_unet, gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2steps_custom(model, device, training_ds, constants, batch_size, epochs, lr, validation_ds):    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    n_samples = training_ds.n_samples\n",
    "    n_samples_val = validation_ds.n_samples\n",
    "    num_nodes = training_ds.nodes\n",
    "    num_constants = constants.shape[1]\n",
    "    out_features = training_ds.out_features\n",
    "    \n",
    "    constants_expanded = constants.expand(batch_size, num_nodes, num_constants)\n",
    "    constants1 = constants_expanded.to(device)\n",
    "    idxs_val = validation_ds.idxs\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('\\rEpoch : {}'.format(epoch), end=\"\")\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()  \n",
    "        \n",
    "        random.shuffle(training_ds.idxs)\n",
    "        idxs = training_ds.idxs\n",
    "        \n",
    "        batch_idx = 0\n",
    "        times_read = []\n",
    "        for i in range(0, n_samples - batch_size, batch_size):\n",
    "            i_next = min(i + batch_size, n_samples)\n",
    "            \n",
    "            if len(idxs[i:i_next]) < batch_size:\n",
    "                constants_expanded = contants.expand(len(idxs[i:i_next]), num_nodes, num_constants)\n",
    "                constants1 = constants_expanded.to(device)\n",
    "        \n",
    "            \n",
    "            t1 = time.time()\n",
    "            batch, labels = training_ds[idxs[i:i_next]]\n",
    "            \n",
    "            t2 = time.time()\n",
    "            \n",
    "            # Transfer to GPU\n",
    "            \n",
    "            \n",
    "            batch1 = torch.cat((batch[0], constants_expanded), dim=2).to(device)\n",
    "            label1 = labels[0].to(device)\n",
    "            label2 = labels[1].to(device)\n",
    "            \n",
    "            \n",
    "            t3 = time.time()\n",
    "            batch_size = batch1.shape[0]\n",
    "            \n",
    "            # Model\n",
    "            \n",
    "            t4 = time.time()\n",
    "            output1 = model(batch1)  \n",
    "            t5 = time.time()\n",
    "            batch2 = torch.cat((output1, label1[:,:,-1].view(-1, num_nodes, 1), constants1), dim=2)\n",
    "            t6 = time.time()\n",
    "            output2 = model(batch2)\n",
    "            t7 = time.time()\n",
    "            loss = criterion(output1, label1[:,:,:out_features]) + criterion(output2, label2)\n",
    "            t8 = time.time()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * batch_size\n",
    "            \n",
    "            \n",
    "            print('\\nTime to read batch: {}s'.format(t2-t1))\n",
    "            print('Time to transfer data to GPU: {}s'.format(t3-t2))\n",
    "            print('Time to process input 1: {}s'.format(t5-t4))\n",
    "            print('Time to process input 2: {}s'.format(t7-t6))\n",
    "            print('Time to compute loss: {}s'.format(t8-t7))\n",
    "            print('\\n')\n",
    "            print('\\rBatch idx: {}; Loss: {:.3f}'.format(batch_idx, train_loss/(batch_size*(batch_idx+1))), end=\"\")\n",
    "            times_read.append(t2-t1)\n",
    "            \n",
    "            if len(times_read) == 10: \n",
    "                print('Reading time: {} +- {}'.format(np.mean(times_read), np.std(times_read)))\n",
    "                return times_read\n",
    "            batch_idx += 1\n",
    "        \n",
    "        train_loss = train_loss / n_samples\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        constants1 = constants_expanded.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            index = 0\n",
    "            \n",
    "            for i in range(0, n_samples_val - batch_size, batch_size):\n",
    "                i_next = min(i + batch_size, n_samples_val)\n",
    "\n",
    "                if len(idxs_val[i:i_next]) < batch_size:\n",
    "                    constants_expanded = contants.expand(len(idxs_val[i:i_next]), num_nodes, num_constants)\n",
    "                    constants1 = constants_expanded.to(device)\n",
    "\n",
    "\n",
    "                #t1 = time.time()\n",
    "                batch, labels = validation_ds[idxs_val[i:i_next]]\n",
    "                # Transfer to GPU\n",
    "                batch1 = torch.cat((batch[0], constants_expanded), dim=2).to(device)\n",
    "                label1 = labels[0].to(device)\n",
    "                label2 = labels[1].to(device)\n",
    "\n",
    "                batch_size = batch1.shape[0]\n",
    "                \n",
    "                output1 = model(batch1)\n",
    "                batch2 = torch.cat((output1, label1[:,:,-1].view(-1, num_nodes, 1), constants1), dim=2)\n",
    "                output2 = model(batch2)\n",
    "                \n",
    "                val_loss = val_loss + (criterion(output1, label1[:,:,:out_features]).item() \n",
    "                                       + criterion(output2, label2).item()) * batch_size\n",
    "                index = index + batch_size\n",
    "                \n",
    "        val_loss = val_loss / n_samples_val\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore effect of different parameters on the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class results_time():\n",
    "    def __init__(self, time, chunk_size, memory, standardization):\n",
    "        self.times = time\n",
    "        self.chunk_size = chunk_size\n",
    "        self.loaded_in_memory = memory\n",
    "        self.standardized = standardization\n",
    "        self.mean_time = np.mean(time)\n",
    "        self.std_time = np.std(time)\n",
    "        self.max_time = np.max(time)\n",
    "        self.min_time = np.min(time)\n",
    "        \n",
    "    def print(self):\n",
    "        print('Parameters: \\n\\t* Chunk size: {}\\n\\t* Loaded in memory: {}\\n\\t* Previously standardized: {}'.\\\n",
    "             format(self.chunk_size, self.loaded_in_memory, self.standardized))\n",
    "        print('Loading time: {:.3f}s $\\pm$ {:.3f}'.format(self.mean_time, self.std_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison(chunk_size, load_ram, data_standardized, chunk=True):\n",
    "    if chunk:\n",
    "        z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', \\\n",
    "                             chunks={'time':chunk_size}, parallel=False).rename({'z':'z500'})\n",
    "        t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords', \\\n",
    "                                 chunks={'time':chunk_size}, parallel=False).rename({'t':'t850'})\n",
    "        rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords', \\\n",
    "                                chunks={'time':chunk_size}, parallel=False)\n",
    "    else:\n",
    "        z500 = xr.open_mfdataset(f'{input_dir}geopotential_500/*.nc', combine='by_coords', \\\n",
    "                             parallel=False).rename({'z':'z500'})\n",
    "        t850 = xr.open_mfdataset(f'{input_dir}temperature_850/*.nc', combine='by_coords', \\\n",
    "                                 parallel=False).rename({'t':'t850'})\n",
    "        rad = xr.open_mfdataset(f'{input_dir}toa_incident_solar_radiation/*.nc', combine='by_coords', \\\n",
    "                                parallel=False)\n",
    "\n",
    "    z500 = z500.isel(time=slice(7, None))\n",
    "    t850 = t850.isel(time=slice(7, None))\n",
    "\n",
    "    constants = xr.open_dataset(f'{input_dir}constants/constants_5.625deg_standardized.nc')\n",
    "    orog = constants['orog']\n",
    "    lsm = constants['lsm']\n",
    "    lats = constants['lat2d']\n",
    "    slt = constants['slt']\n",
    "    cos_lon = constants['cos_lon']\n",
    "    sin_lon = constants['sin_lon']\n",
    "\n",
    "    num_constants = len([orog, lats, lsm, slt])\n",
    "    constants_tensor = torch.tensor(xr.merge([orog, lats, lsm, slt], compat='override').to_array().values, \\\n",
    "                                dtype=torch.float)\n",
    "    \n",
    "    \n",
    "    in_features = 7 #len(feature_idx)\n",
    "    train_mean_ = xr.open_mfdataset(f'{input_dir}mean_train_features_dynamic.nc')\n",
    "    train_std_ = xr.open_mfdataset(f'{input_dir}std_train_features_dynamic.nc')\n",
    "    \n",
    "    if data_standardized:\n",
    "        ds = xr.merge([z500, t850, rad], compat='override')\n",
    "        #ds = xr.merge([z500, t850, orog, lats, lsm, slt, rad], compat='override')\n",
    "\n",
    "        ds_train = ds.sel(time=slice(*train_years))\n",
    "        ds_valid = ds.sel(time=slice(*val_years))\n",
    "        ds_test = ds.sel(time=slice(*test_years))\n",
    "    \n",
    "    else:\n",
    "        ds = xr.open_mfdataset(f'{input_dir}ds_standardized.nc')\n",
    "\n",
    "        ds_train = ds.sel(time=slice(*train_years))\n",
    "        ds_valid = ds.sel(time=slice(*val_years))\n",
    "        ds_test = ds.sel(time=slice(*test_years))\n",
    "    \n",
    "    # Train and validation data\n",
    "    training_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_train, out_features=out_features, delta_t=delta_t,\n",
    "                                                       len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                       years=train_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                       mean=train_mean_, std=train_std_, load=load_ram, standardize=data_standardized)\n",
    "    validation_ds = WeatherBenchDatasetXarrayHealpixTemp(ds=ds_valid, out_features=out_features, delta_t=delta_t,\n",
    "                                                         len_sqce=len_sqce, max_lead_time=max_lead_time,\n",
    "                                                         years=val_years, nodes=nodes, nb_timesteps=nb_timesteps, \n",
    "                                                         mean=train_mean_, std=train_std_, load=load_ram, standardize=data_standardized)\n",
    "\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    times1 = train_model_2steps_custom(spherical_unet, device, training_ds, constants_tensor.transpose(1,0), batch_size, epochs=7, \\\n",
    "                                           lr=learning_rate, validation_ds=validation_ds)\n",
    "    \n",
    "    del z500, t850, ds, ds_train, ds_valid, ds_test, training_ds, validation_ds\n",
    "    return times1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1. \n",
    "\n",
    "* chunk size = 521\n",
    "* data loaded to memory = False\n",
    "* data previously standardized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483\n",
    "load_ram = False\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 3.419006586074829s\n",
      "Time to transfer data to GPU: 0.017685651779174805s\n",
      "Time to process input 1: 2.754517078399658s\n",
      "Time to process input 2: 0.10320544242858887s\n",
      "Time to compute loss: 0.04997611045837402s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 21.044\n",
      "Time to read batch: 2.7278189659118652s\n",
      "Time to transfer data to GPU: 0.004885435104370117s\n",
      "Time to process input 1: 0.04137897491455078s\n",
      "Time to process input 2: 0.03589057922363281s\n",
      "Time to compute loss: 0.15802240371704102s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 15.557\n",
      "Time to read batch: 2.5874085426330566s\n",
      "Time to transfer data to GPU: 0.005301475524902344s\n",
      "Time to process input 1: 0.047299861907958984s\n",
      "Time to process input 2: 0.043466806411743164s\n",
      "Time to compute loss: 0.1377248764038086s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 12.312\n",
      "Time to read batch: 2.4888930320739746s\n",
      "Time to transfer data to GPU: 0.004891872406005859s\n",
      "Time to process input 1: 0.048787593841552734s\n",
      "Time to process input 2: 0.04067730903625488s\n",
      "Time to compute loss: 0.14659357070922852s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 10.217\n",
      "Time to read batch: 2.6198930740356445s\n",
      "Time to transfer data to GPU: 0.0048370361328125s\n",
      "Time to process input 1: 0.04358243942260742s\n",
      "Time to process input 2: 0.04272150993347168s\n",
      "Time to compute loss: 0.14441180229187012s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 8.644\n",
      "Time to read batch: 2.535961389541626s\n",
      "Time to transfer data to GPU: 0.004978179931640625s\n",
      "Time to process input 1: 0.0425260066986084s\n",
      "Time to process input 2: 0.04334402084350586s\n",
      "Time to compute loss: 0.14431524276733398s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 7.531\n",
      "Time to read batch: 2.553500175476074s\n",
      "Time to transfer data to GPU: 0.004973173141479492s\n",
      "Time to process input 1: 0.0458836555480957s\n",
      "Time to process input 2: 0.04090714454650879s\n",
      "Time to compute loss: 0.14438080787658691s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 6.717\n",
      "Time to read batch: 2.4100306034088135s\n",
      "Time to transfer data to GPU: 0.0049457550048828125s\n",
      "Time to process input 1: 0.04241943359375s\n",
      "Time to process input 2: 0.04142355918884277s\n",
      "Time to compute loss: 0.1481623649597168s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 6.101\n",
      "Time to read batch: 2.556650161743164s\n",
      "Time to transfer data to GPU: 0.004713773727416992s\n",
      "Time to process input 1: 0.04452991485595703s\n",
      "Time to process input 2: 0.04107046127319336s\n",
      "Time to compute loss: 0.14434480667114258s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 5.610\n",
      "Time to read batch: 2.2791037559509277s\n",
      "Time to transfer data to GPU: 0.005052089691162109s\n",
      "Time to process input 1: 0.04558396339416504s\n",
      "Time to process input 2: 0.04288005828857422s\n",
      "Time to compute loss: 0.14407849311828613s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 5.212Reading time: 2.6178266286849974 +- 0.29052293946709845\n"
     ]
    }
   ],
   "source": [
    "times1 = generate_comparison(chunk_size, load_ram, data_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2. \n",
    "\n",
    "* chunk size = 521\n",
    "* data loaded to memory = True\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483\n",
    "load_ram = True\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to RAM...\n",
      "Loading data to RAM...\n",
      "Epoch : 0\n",
      "Time to read batch: 0.01496434211730957s\n",
      "Time to transfer data to GPU: 0.0043544769287109375s\n",
      "Time to process input 1: 0.14259696006774902s\n",
      "Time to process input 2: 0.10696983337402344s\n",
      "Time to compute loss: 0.05048060417175293s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 1.618\n",
      "Time to read batch: 0.04442238807678223s\n",
      "Time to transfer data to GPU: 0.021195173263549805s\n",
      "Time to process input 1: 0.037370920181274414s\n",
      "Time to process input 2: 0.03946328163146973s\n",
      "Time to compute loss: 0.15044331550598145s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 2.578\n",
      "Time to read batch: 0.04675745964050293s\n",
      "Time to transfer data to GPU: 0.01607823371887207s\n",
      "Time to process input 1: 0.0394594669342041s\n",
      "Time to process input 2: 0.040471553802490234s\n",
      "Time to compute loss: 0.14900612831115723s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 2.583\n",
      "Time to read batch: 0.025327444076538086s\n",
      "Time to transfer data to GPU: 0.004659414291381836s\n",
      "Time to process input 1: 0.03720903396606445s\n",
      "Time to process input 2: 0.04345583915710449s\n",
      "Time to compute loss: 0.1451418399810791s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 2.546\n",
      "Time to read batch: 0.024859905242919922s\n",
      "Time to transfer data to GPU: 0.0045964717864990234s\n",
      "Time to process input 1: 0.03348207473754883s\n",
      "Time to process input 2: 0.03650522232055664s\n",
      "Time to compute loss: 0.15477204322814941s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 2.399\n",
      "Time to read batch: 0.04080557823181152s\n",
      "Time to transfer data to GPU: 0.004612445831298828s\n",
      "Time to process input 1: 0.037360191345214844s\n",
      "Time to process input 2: 0.05066084861755371s\n",
      "Time to compute loss: 0.13953351974487305s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 2.251\n",
      "Time to read batch: 0.02634143829345703s\n",
      "Time to transfer data to GPU: 0.004561662673950195s\n",
      "Time to process input 1: 0.03803443908691406s\n",
      "Time to process input 2: 0.041161298751831055s\n",
      "Time to compute loss: 0.1468489170074463s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 2.164\n",
      "Time to read batch: 0.02420496940612793s\n",
      "Time to transfer data to GPU: 0.00452113151550293s\n",
      "Time to process input 1: 0.03505539894104004s\n",
      "Time to process input 2: 0.03853273391723633s\n",
      "Time to compute loss: 0.15136313438415527s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 2.092\n",
      "Time to read batch: 0.022254228591918945s\n",
      "Time to transfer data to GPU: 0.004582643508911133s\n",
      "Time to process input 1: 0.036736488342285156s\n",
      "Time to process input 2: 0.0411524772644043s\n",
      "Time to compute loss: 0.14586257934570312s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 2.023\n",
      "Time to read batch: 0.022361040115356445s\n",
      "Time to transfer data to GPU: 0.004532575607299805s\n",
      "Time to process input 1: 0.03723478317260742s\n",
      "Time to process input 2: 0.03922414779663086s\n",
      "Time to compute loss: 0.1497507095336914s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 1.954Reading time: 0.02922987937927246 +- 0.0101945568406105\n"
     ]
    }
   ],
   "source": [
    "times2 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3. \n",
    "\n",
    "* chunk size = 1042\n",
    "* data loaded to memory = False\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1042#483*2 #483\n",
    "load_ram = False\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 5.038513660430908s\n",
      "Time to transfer data to GPU: 0.0050580501556396484s\n",
      "Time to process input 1: 0.1417396068572998s\n",
      "Time to process input 2: 0.14063715934753418s\n",
      "Time to compute loss: 0.03820323944091797s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 1.344\n",
      "Time to read batch: 4.678669691085815s\n",
      "Time to transfer data to GPU: 0.005233049392700195s\n",
      "Time to process input 1: 0.04192686080932617s\n",
      "Time to process input 2: 0.04330945014953613s\n",
      "Time to compute loss: 0.14320993423461914s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 4.119\n",
      "Time to read batch: 5.5206780433654785s\n",
      "Time to transfer data to GPU: 0.00513148307800293s\n",
      "Time to process input 1: 0.04539132118225098s\n",
      "Time to process input 2: 0.041292428970336914s\n",
      "Time to compute loss: 0.14367341995239258s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 3.327\n",
      "Time to read batch: 5.225013017654419s\n",
      "Time to transfer data to GPU: 0.005410194396972656s\n",
      "Time to process input 1: 0.04780411720275879s\n",
      "Time to process input 2: 0.04814791679382324s\n",
      "Time to compute loss: 0.14158368110656738s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 2.924\n",
      "Time to read batch: 4.910983324050903s\n",
      "Time to transfer data to GPU: 0.005178928375244141s\n",
      "Time to process input 1: 0.04188823699951172s\n",
      "Time to process input 2: 0.04249715805053711s\n",
      "Time to compute loss: 0.1524343490600586s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 2.771\n",
      "Time to read batch: 5.176609516143799s\n",
      "Time to transfer data to GPU: 0.005246400833129883s\n",
      "Time to process input 1: 0.04077434539794922s\n",
      "Time to process input 2: 0.03840947151184082s\n",
      "Time to compute loss: 0.14964032173156738s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 2.673\n",
      "Time to read batch: 5.189894437789917s\n",
      "Time to transfer data to GPU: 0.004861593246459961s\n",
      "Time to process input 1: 0.04125690460205078s\n",
      "Time to process input 2: 0.04239249229431152s\n",
      "Time to compute loss: 0.14598631858825684s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 2.570\n",
      "Time to read batch: 5.18673849105835s\n",
      "Time to transfer data to GPU: 0.004757404327392578s\n",
      "Time to process input 1: 0.04119992256164551s\n",
      "Time to process input 2: 0.03955578804016113s\n",
      "Time to compute loss: 0.16409587860107422s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 2.481\n",
      "Time to read batch: 5.053095817565918s\n",
      "Time to transfer data to GPU: 0.0052242279052734375s\n",
      "Time to process input 1: 0.04373288154602051s\n",
      "Time to process input 2: 0.03862190246582031s\n",
      "Time to compute loss: 0.150315523147583s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 2.408\n",
      "Time to read batch: 4.837523937225342s\n",
      "Time to transfer data to GPU: 0.004708051681518555s\n",
      "Time to process input 1: 0.039145708084106445s\n",
      "Time to process input 2: 0.0378568172454834s\n",
      "Time to compute loss: 0.15012788772583008s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 2.330Reading time: 5.081771993637085 +- 0.2233539905941481\n"
     ]
    }
   ],
   "source": [
    "times3 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 4. \n",
    "\n",
    "* chunk size = 1042\n",
    "* data loaded to memory = True\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521*2#483*2 #483\n",
    "load_ram = True\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to RAM...\n",
      "Loading data to RAM...\n",
      "Epoch : 0\n",
      "Time to read batch: 0.06084752082824707s\n",
      "Time to transfer data to GPU: 0.004936695098876953s\n",
      "Time to process input 1: 0.15724921226501465s\n",
      "Time to process input 2: 0.11062240600585938s\n",
      "Time to compute loss: 0.04253649711608887s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 1.578\n",
      "Time to read batch: 0.025967121124267578s\n",
      "Time to transfer data to GPU: 0.00445556640625s\n",
      "Time to process input 1: 0.03679609298706055s\n",
      "Time to process input 2: 0.04136204719543457s\n",
      "Time to compute loss: 0.1475214958190918s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 2.405\n",
      "Time to read batch: 0.022838592529296875s\n",
      "Time to transfer data to GPU: 0.004541873931884766s\n",
      "Time to process input 1: 0.0363919734954834s\n",
      "Time to process input 2: 0.03941154479980469s\n",
      "Time to compute loss: 0.14887571334838867s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 2.217\n",
      "Time to read batch: 0.022765636444091797s\n",
      "Time to transfer data to GPU: 0.004614830017089844s\n",
      "Time to process input 1: 0.04070091247558594s\n",
      "Time to process input 2: 0.03920435905456543s\n",
      "Time to compute loss: 0.14553546905517578s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 2.020\n",
      "Time to read batch: 0.031792640686035156s\n",
      "Time to transfer data to GPU: 0.0048236846923828125s\n",
      "Time to process input 1: 0.039639949798583984s\n",
      "Time to process input 2: 0.04240536689758301s\n",
      "Time to compute loss: 0.1460731029510498s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 2.005\n",
      "Time to read batch: 0.024330615997314453s\n",
      "Time to transfer data to GPU: 0.0047914981842041016s\n",
      "Time to process input 1: 0.04033970832824707s\n",
      "Time to process input 2: 0.04123497009277344s\n",
      "Time to compute loss: 0.1489574909210205s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 1.963\n",
      "Time to read batch: 0.024997234344482422s\n",
      "Time to transfer data to GPU: 0.004718303680419922s\n",
      "Time to process input 1: 0.037786245346069336s\n",
      "Time to process input 2: 0.03954935073852539s\n",
      "Time to compute loss: 0.1480720043182373s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 1.911\n",
      "Time to read batch: 0.022870540618896484s\n",
      "Time to transfer data to GPU: 0.00475764274597168s\n",
      "Time to process input 1: 0.04206728935241699s\n",
      "Time to process input 2: 0.040865421295166016s\n",
      "Time to compute loss: 0.1447131633758545s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 1.842\n",
      "Time to read batch: 0.02754354476928711s\n",
      "Time to transfer data to GPU: 0.004692554473876953s\n",
      "Time to process input 1: 0.038628578186035156s\n",
      "Time to process input 2: 0.052083730697631836s\n",
      "Time to compute loss: 0.1344912052154541s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 1.776\n",
      "Time to read batch: 0.042619943618774414s\n",
      "Time to transfer data to GPU: 0.0053746700286865234s\n",
      "Time to process input 1: 0.039764404296875s\n",
      "Time to process input 2: 0.04068803787231445s\n",
      "Time to compute loss: 0.1479344367980957s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 1.722Reading time: 0.030657339096069335 +- 0.011591565724850362\n"
     ]
    }
   ],
   "source": [
    "times4 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 5. \n",
    "\n",
    "* chunk size = 483*2\n",
    "* data loaded to memory = False\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 483*2#483*2 #483\n",
    "load_ram = False\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 4.467376470565796s\n",
      "Time to transfer data to GPU: 0.004725217819213867s\n",
      "Time to process input 1: 0.1329643726348877s\n",
      "Time to process input 2: 0.1218101978302002s\n",
      "Time to compute loss: 0.03996849060058594s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 1.254\n",
      "Time to read batch: 4.220887184143066s\n",
      "Time to transfer data to GPU: 0.005463361740112305s\n",
      "Time to process input 1: 0.04322171211242676s\n",
      "Time to process input 2: 0.041930437088012695s\n",
      "Time to compute loss: 0.14554357528686523s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 1.553\n",
      "Time to read batch: 3.678936004638672s\n",
      "Time to transfer data to GPU: 0.005243062973022461s\n",
      "Time to process input 1: 0.04355621337890625s\n",
      "Time to process input 2: 0.043515920639038086s\n",
      "Time to compute loss: 0.14034295082092285s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 1.522\n",
      "Time to read batch: 3.908228635787964s\n",
      "Time to transfer data to GPU: 0.005069732666015625s\n",
      "Time to process input 1: 0.04314708709716797s\n",
      "Time to process input 2: 0.03963589668273926s\n",
      "Time to compute loss: 0.14670014381408691s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 1.431\n",
      "Time to read batch: 3.9779791831970215s\n",
      "Time to transfer data to GPU: 0.004796504974365234s\n",
      "Time to process input 1: 0.04375815391540527s\n",
      "Time to process input 2: 0.04850339889526367s\n",
      "Time to compute loss: 0.13713812828063965s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 1.372\n",
      "Time to read batch: 4.024517059326172s\n",
      "Time to transfer data to GPU: 0.005362749099731445s\n",
      "Time to process input 1: 0.04425382614135742s\n",
      "Time to process input 2: 0.0439610481262207s\n",
      "Time to compute loss: 0.14360499382019043s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 1.339\n",
      "Time to read batch: 4.208114147186279s\n",
      "Time to transfer data to GPU: 0.004834651947021484s\n",
      "Time to process input 1: 0.04082036018371582s\n",
      "Time to process input 2: 0.04194235801696777s\n",
      "Time to compute loss: 0.14482474327087402s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 1.287\n",
      "Time to read batch: 3.566190719604492s\n",
      "Time to transfer data to GPU: 0.005094766616821289s\n",
      "Time to process input 1: 0.04014730453491211s\n",
      "Time to process input 2: 0.040206193923950195s\n",
      "Time to compute loss: 0.14903831481933594s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 1.241\n",
      "Time to read batch: 3.5777220726013184s\n",
      "Time to transfer data to GPU: 0.004721403121948242s\n",
      "Time to process input 1: 0.04258155822753906s\n",
      "Time to process input 2: 0.039071083068847656s\n",
      "Time to compute loss: 0.14905905723571777s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 1.206\n",
      "Time to read batch: 4.6752259731292725s\n",
      "Time to transfer data to GPU: 0.005414009094238281s\n",
      "Time to process input 1: 0.04406285285949707s\n",
      "Time to process input 2: 0.040731191635131836s\n",
      "Time to compute loss: 0.15728330612182617s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 1.182Reading time: 4.030517745018005 +- 0.35160480848497844\n"
     ]
    }
   ],
   "source": [
    "times5 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 6. \n",
    "\n",
    "* chunk size = 521\n",
    "* data loaded to memory = False\n",
    "* data previously standardized = True --> data_standardized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483\n",
    "load_ram = False\n",
    "data_standardized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 16.40645933151245s\n",
      "Time to transfer data to GPU: 0.010524988174438477s\n",
      "Time to process input 1: 0.15302515029907227s\n",
      "Time to process input 2: 0.08313894271850586s\n",
      "Time to compute loss: 0.07191610336303711s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 3679.374\n",
      "Time to read batch: 16.69389009475708s\n",
      "Time to transfer data to GPU: 0.0060651302337646484s\n",
      "Time to process input 1: 0.040924072265625s\n",
      "Time to process input 2: 0.04015660285949707s\n",
      "Time to compute loss: 0.1479175090789795s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 3648.454\n",
      "Time to read batch: 16.5794780254364s\n",
      "Time to transfer data to GPU: 0.0057947635650634766s\n",
      "Time to process input 1: 0.039808034896850586s\n",
      "Time to process input 2: 0.037888288497924805s\n",
      "Time to compute loss: 0.1605701446533203s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 3617.992\n",
      "Time to read batch: 17.111807823181152s\n",
      "Time to transfer data to GPU: 0.01013636589050293s\n",
      "Time to process input 1: 0.04415488243103027s\n",
      "Time to process input 2: 0.041107177734375s\n",
      "Time to compute loss: 0.1493368148803711s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 3587.485\n",
      "Time to read batch: 17.311199426651s\n",
      "Time to transfer data to GPU: 0.006112575531005859s\n",
      "Time to process input 1: 0.04273247718811035s\n",
      "Time to process input 2: 0.037008047103881836s\n",
      "Time to compute loss: 0.15176892280578613s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 3556.915\n",
      "Time to read batch: 16.549987316131592s\n",
      "Time to transfer data to GPU: 0.018503427505493164s\n",
      "Time to process input 1: 0.0499725341796875s\n",
      "Time to process input 2: 0.040503501892089844s\n",
      "Time to compute loss: 0.15700674057006836s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 3526.346\n",
      "Time to read batch: 16.639952182769775s\n",
      "Time to transfer data to GPU: 0.005261421203613281s\n",
      "Time to process input 1: 0.038765907287597656s\n",
      "Time to process input 2: 0.038625478744506836s\n",
      "Time to compute loss: 0.15073418617248535s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 3495.924\n",
      "Time to read batch: 16.563703060150146s\n",
      "Time to transfer data to GPU: 0.005913734436035156s\n",
      "Time to process input 1: 0.043348073959350586s\n",
      "Time to process input 2: 0.03718376159667969s\n",
      "Time to compute loss: 0.1528928279876709s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 3465.723\n",
      "Time to read batch: 16.643502235412598s\n",
      "Time to transfer data to GPU: 0.006540060043334961s\n",
      "Time to process input 1: 0.03733181953430176s\n",
      "Time to process input 2: 0.036278724670410156s\n",
      "Time to compute loss: 0.16449713706970215s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 3435.202\n",
      "Time to read batch: 16.839534997940063s\n",
      "Time to transfer data to GPU: 0.005967855453491211s\n",
      "Time to process input 1: 0.04273486137390137s\n",
      "Time to process input 2: 0.0502314567565918s\n",
      "Time to compute loss: 0.1404261589050293s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 3404.560Reading time: 16.733951449394226 +- 0.2645185870793179\n"
     ]
    }
   ],
   "source": [
    "times6 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 7. \n",
    "\n",
    "* chunk size = 521\n",
    "* data loaded to memory = True\n",
    "* data previously standardized = True --> data_standardized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 521#483*2 #483\n",
    "load_ram = True\n",
    "data_standardized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to RAM...\n",
      "Loading data to RAM...\n",
      "Epoch : 0\n",
      "Time to read batch: 0.03540205955505371s\n",
      "Time to transfer data to GPU: 0.020819425582885742s\n",
      "Time to process input 1: 0.11373329162597656s\n",
      "Time to process input 2: 0.10968923568725586s\n",
      "Time to compute loss: 0.05250096321105957s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 3068.629\n",
      "Time to read batch: 0.015705585479736328s\n",
      "Time to transfer data to GPU: 0.0044286251068115234s\n",
      "Time to process input 1: 0.036890268325805664s\n",
      "Time to process input 2: 0.039411067962646484s\n",
      "Time to compute loss: 0.15049958229064941s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 3040.797\n",
      "Time to read batch: 0.013686895370483398s\n",
      "Time to transfer data to GPU: 0.004465818405151367s\n",
      "Time to process input 1: 0.03734326362609863s\n",
      "Time to process input 2: 0.03717613220214844s\n",
      "Time to compute loss: 0.15335655212402344s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 3010.812\n",
      "Time to read batch: 0.013140678405761719s\n",
      "Time to transfer data to GPU: 0.004460334777832031s\n",
      "Time to process input 1: 0.03710055351257324s\n",
      "Time to process input 2: 0.04009556770324707s\n",
      "Time to compute loss: 0.14928984642028809s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 2978.731\n",
      "Time to read batch: 0.013588666915893555s\n",
      "Time to transfer data to GPU: 0.0044977664947509766s\n",
      "Time to process input 1: 0.0361180305480957s\n",
      "Time to process input 2: 0.03854227066040039s\n",
      "Time to compute loss: 0.15099525451660156s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 2946.653\n",
      "Time to read batch: 0.013606071472167969s\n",
      "Time to transfer data to GPU: 0.004505634307861328s\n",
      "Time to process input 1: 0.03708982467651367s\n",
      "Time to process input 2: 0.03849363327026367s\n",
      "Time to compute loss: 0.15303492546081543s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 2914.058\n",
      "Time to read batch: 0.01376199722290039s\n",
      "Time to transfer data to GPU: 0.004683017730712891s\n",
      "Time to process input 1: 0.039170026779174805s\n",
      "Time to process input 2: 0.038397789001464844s\n",
      "Time to compute loss: 0.1500413417816162s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 2881.630\n",
      "Time to read batch: 0.015449285507202148s\n",
      "Time to transfer data to GPU: 0.004602193832397461s\n",
      "Time to process input 1: 0.0416712760925293s\n",
      "Time to process input 2: 0.03808474540710449s\n",
      "Time to compute loss: 0.14791369438171387s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 2849.144\n",
      "Time to read batch: 0.015260457992553711s\n",
      "Time to transfer data to GPU: 0.004553318023681641s\n",
      "Time to process input 1: 0.03676414489746094s\n",
      "Time to process input 2: 0.03334689140319824s\n",
      "Time to compute loss: 0.1547396183013916s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 2816.530\n",
      "Time to read batch: 0.03588128089904785s\n",
      "Time to transfer data to GPU: 0.01622772216796875s\n",
      "Time to process input 1: 0.03933548927307129s\n",
      "Time to process input 2: 0.0394282341003418s\n",
      "Time to compute loss: 0.15004491806030273s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 2783.888Reading time: 0.018548297882080077 +- 0.0085894363227467\n"
     ]
    }
   ],
   "source": [
    "times7 = generate_comparison(chunk_size, load_ram, data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 8. \n",
    "\n",
    "* chunk size = No chunking\n",
    "* data loaded to memory = False\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 0#483*2 #483\n",
    "load_ram = False\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Time to read batch: 29.508171319961548s\n",
      "Time to transfer data to GPU: 0.020882606506347656s\n",
      "Time to process input 1: 0.1598670482635498s\n",
      "Time to process input 2: 0.11409187316894531s\n",
      "Time to compute loss: 0.04235720634460449s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 281.655\n",
      "Time to read batch: 36.39236617088318s\n",
      "Time to transfer data to GPU: 0.014907598495483398s\n",
      "Time to process input 1: 0.06324267387390137s\n",
      "Time to process input 2: 0.0420374870300293s\n",
      "Time to compute loss: 0.16190505027770996s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 246.762\n",
      "Time to read batch: 35.60328912734985s\n",
      "Time to transfer data to GPU: 0.020716428756713867s\n",
      "Time to process input 1: 0.045294761657714844s\n",
      "Time to process input 2: 0.0397646427154541s\n",
      "Time to compute loss: 0.1466660499572754s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 216.223\n",
      "Time to read batch: 33.10098910331726s\n",
      "Time to transfer data to GPU: 0.01052999496459961s\n",
      "Time to process input 1: 0.06509852409362793s\n",
      "Time to process input 2: 0.04654264450073242s\n",
      "Time to compute loss: 0.1512775421142578s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 193.334\n",
      "Time to read batch: 29.904471158981323s\n",
      "Time to transfer data to GPU: 0.030745506286621094s\n",
      "Time to process input 1: 0.04450178146362305s\n",
      "Time to process input 2: 0.03851723670959473s\n",
      "Time to compute loss: 0.15129923820495605s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 175.970\n",
      "Time to read batch: 31.929181575775146s\n",
      "Time to transfer data to GPU: 0.008831501007080078s\n",
      "Time to process input 1: 0.05820965766906738s\n",
      "Time to process input 2: 0.03959798812866211s\n",
      "Time to compute loss: 0.16029000282287598s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 161.666\n",
      "Time to read batch: 36.24795460700989s\n",
      "Time to transfer data to GPU: 0.020735740661621094s\n",
      "Time to process input 1: 0.04757976531982422s\n",
      "Time to process input 2: 0.04088449478149414s\n",
      "Time to compute loss: 0.1484830379486084s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 149.498\n",
      "Time to read batch: 37.469783544540405s\n",
      "Time to transfer data to GPU: 0.020344257354736328s\n",
      "Time to process input 1: 0.059534549713134766s\n",
      "Time to process input 2: 0.0379641056060791s\n",
      "Time to compute loss: 0.16205644607543945s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 139.192\n",
      "Time to read batch: 35.08887720108032s\n",
      "Time to transfer data to GPU: 0.010751724243164062s\n",
      "Time to process input 1: 0.06613421440124512s\n",
      "Time to process input 2: 0.04143118858337402s\n",
      "Time to compute loss: 0.17152738571166992s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 130.142\n",
      "Time to read batch: 33.81058979034424s\n",
      "Time to transfer data to GPU: 0.021744251251220703s\n",
      "Time to process input 1: 0.05425524711608887s\n",
      "Time to process input 2: 0.039994239807128906s\n",
      "Time to compute loss: 0.14556455612182617s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 122.218Reading time: 33.90556735992432 +- 2.6184994777722936\n"
     ]
    }
   ],
   "source": [
    "times8 = generate_comparison(chunk_size, load_ram, data_standardized, chunk=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 9. \n",
    "\n",
    "* chunk size = No chunking\n",
    "* data loaded to memory = True\n",
    "* data previously standardized = False --> data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 0#483*2 #483\n",
    "load_ram = True\n",
    "data_standardized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to RAM...\n",
      "Loading data to RAM...\n",
      "Epoch : 0\n",
      "Time to read batch: 0.018594741821289062s\n",
      "Time to transfer data to GPU: 0.004164695739746094s\n",
      "Time to process input 1: 0.15126490592956543s\n",
      "Time to process input 2: 0.11709141731262207s\n",
      "Time to compute loss: 0.04013204574584961s\n",
      "\n",
      "\n",
      "Batch idx: 0; Loss: 43.448\n",
      "Time to read batch: 0.051525115966796875s\n",
      "Time to transfer data to GPU: 0.004364013671875s\n",
      "Time to process input 1: 0.0355229377746582s\n",
      "Time to process input 2: 0.0403444766998291s\n",
      "Time to compute loss: 0.14962267875671387s\n",
      "\n",
      "\n",
      "Batch idx: 1; Loss: 38.708\n",
      "Time to read batch: 0.023848533630371094s\n",
      "Time to transfer data to GPU: 0.00469970703125s\n",
      "Time to process input 1: 0.037389516830444336s\n",
      "Time to process input 2: 0.04007863998413086s\n",
      "Time to compute loss: 0.1486983299255371s\n",
      "\n",
      "\n",
      "Batch idx: 2; Loss: 34.891\n",
      "Time to read batch: 0.019304990768432617s\n",
      "Time to transfer data to GPU: 0.004502534866333008s\n",
      "Time to process input 1: 0.036222219467163086s\n",
      "Time to process input 2: 0.03931140899658203s\n",
      "Time to compute loss: 0.14876770973205566s\n",
      "\n",
      "\n",
      "Batch idx: 3; Loss: 31.800\n",
      "Time to read batch: 0.04175305366516113s\n",
      "Time to transfer data to GPU: 0.004509449005126953s\n",
      "Time to process input 1: 0.044628143310546875s\n",
      "Time to process input 2: 0.03989434242248535s\n",
      "Time to compute loss: 0.14020800590515137s\n",
      "\n",
      "\n",
      "Batch idx: 4; Loss: 28.993\n",
      "Time to read batch: 0.022339582443237305s\n",
      "Time to transfer data to GPU: 0.004724979400634766s\n",
      "Time to process input 1: 0.037915945053100586s\n",
      "Time to process input 2: 0.039344072341918945s\n",
      "Time to compute loss: 0.15078377723693848s\n",
      "\n",
      "\n",
      "Batch idx: 5; Loss: 26.538\n",
      "Time to read batch: 0.02237391471862793s\n",
      "Time to transfer data to GPU: 0.004499673843383789s\n",
      "Time to process input 1: 0.03726482391357422s\n",
      "Time to process input 2: 0.04965543746948242s\n",
      "Time to compute loss: 0.1409752368927002s\n",
      "\n",
      "\n",
      "Batch idx: 6; Loss: 24.391\n",
      "Time to read batch: 0.02379894256591797s\n",
      "Time to transfer data to GPU: 0.00452113151550293s\n",
      "Time to process input 1: 0.036872148513793945s\n",
      "Time to process input 2: 0.03877425193786621s\n",
      "Time to compute loss: 0.14943742752075195s\n",
      "\n",
      "\n",
      "Batch idx: 7; Loss: 22.517\n",
      "Time to read batch: 0.02718973159790039s\n",
      "Time to transfer data to GPU: 0.004573345184326172s\n",
      "Time to process input 1: 0.0386965274810791s\n",
      "Time to process input 2: 0.040895700454711914s\n",
      "Time to compute loss: 0.14458537101745605s\n",
      "\n",
      "\n",
      "Batch idx: 8; Loss: 20.856\n",
      "Time to read batch: 0.023111820220947266s\n",
      "Time to transfer data to GPU: 0.004769563674926758s\n",
      "Time to process input 1: 0.03859758377075195s\n",
      "Time to process input 2: 0.04148054122924805s\n",
      "Time to compute loss: 0.14759087562561035s\n",
      "\n",
      "\n",
      "Batch idx: 9; Loss: 19.418Reading time: 0.027384042739868164 +- 0.010129033297303245\n"
     ]
    }
   ],
   "source": [
    "times9 = generate_comparison(chunk_size, load_ram, data_standardized, chunk=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'printimes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fe04a33fc207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtimes1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'printimes'"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "for times in [times1, times2, times3, times4, times5, times6, times7, times8, times9]:\n",
    "    t.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_plot = [t1, t2, t3, t4, t5]\n",
    "\n",
    "t_loaded = [t for t in times_plot if t.loaded_in_memory]\n",
    "t_not_loaded = [t for t in times_plot if not t.loaded_in_memory]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ax[0].set_title('Previously load on memory')\n",
    "ax[1].set_title('Loading when required')\n",
    "\n",
    "for i, t_list in enumerate([t_loaded, t_not_loaded]):\n",
    "    ax[i].boxplot([t.times for t in t_list])\n",
    "    ax[i].set_xticklabels([t.chunk_size for t in t_list])\n",
    "    ax[i].set_xlabel('Chunk_size')\n",
    "    ax[i].set_ylabel('Reading time [s]')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_plot = [t1, t2, t6, t7]\n",
    "\n",
    "t_loaded = [t for t in times_plot if t.loaded_in_memory]\n",
    "t_not_loaded = [t for t in times_plot if not t.loaded_in_memory]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ax[0].set_title('Previously load on memory')\n",
    "ax[1].set_title('Loading when required')\n",
    "\n",
    "for i, t_list in enumerate([t_loaded, t_not_loaded]):\n",
    "    ax[i].boxplot([t.times for t in t_list])\n",
    "    ax[i].set_xticklabels([t.standardized for t in t_list])\n",
    "    ax[i].set_xlabel('Previously standardized')\n",
    "    ax[i].set_ylabel('Reading time [s]')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_plot = [t1, t2, t6, t7, t8, t9]\n",
    "\n",
    "t_loaded = [t for t in times_plot if t.loaded_in_memory]\n",
    "t_not_loaded = [t for t in times_plot if not t.loaded_in_memory]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ax[0].set_title('Previously load on memory')\n",
    "ax[1].set_title('Loading when required')\n",
    "\n",
    "for i, t_list in enumerate([t_loaded, t_not_loaded]):\n",
    "    ax[i].boxplot([t.times for t in t_list])\n",
    "    ax[i].set_xticklabels([t.chunk_size for t in t_list])\n",
    "    ax[i].set_xlabel('Chunk_size')\n",
    "    ax[i].set_ylabel('Reading time [s]')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "* Loading the data previously is the most significant difference regarding the total training time.\n",
    "\n",
    "* Chunking the data has a large effect when it is not previously loaded. Also, the chunk size affects the reading time.\n",
    "\n",
    "* Using previously standardized data instead of performing the standardization for each batch helps reducing the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
