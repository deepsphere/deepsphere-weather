{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/'.join(sys.path[0].split('/')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.data import Dataset_WeatherBench_1D, load_test_data\n",
    "from modules.models import SphericalCNN\n",
    "from modules.test import create_predictions, compute_weighted_rmse, assess_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/mnt/scratch/students/illorens/data/5.625deg/\"\n",
    "\n",
    "train_years=('1979', '2015')\n",
    "valid_years=('2016', '2016')\n",
    "test_years=('2017', '2018')\n",
    "vars = ['z', 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_device(model, gpu=None):\n",
    "    \"\"\"Initialize device based on cpu/gpu and number of gpu\n",
    "    Args:\n",
    "        device (str): cpu or gpu\n",
    "        ids (list of int or str): list of gpus that should be used\n",
    "        unet (torch.Module): the model to place on the device(s)\n",
    "    Raises:\n",
    "        Exception: There is an error in configuring the cpu or gpu\n",
    "    Returns:\n",
    "        torch.Module, torch.device: the model placed on device, the device\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        if gpu is None:\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = model.to(device)\n",
    "            model = nn.DataParallel(model)\n",
    "        elif len(gpu) == 1:\n",
    "            device = torch.device(\"cuda:{}\".format(gpu[0]))\n",
    "            model = model.to(device)\n",
    "        else:\n",
    "            device = torch.device(\"cuda:{}\".format(gpu[0]))\n",
    "            model = model.to(device)\n",
    "            model = nn.DataParallel(model, device_ids=[int(i) for i in gpu])\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "    return model, device\n",
    "\n",
    "\n",
    "def train_model(model, device, train_generator, epochs, lr, validation_data, patience):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    #optim.Adam(model.parameters(), lr=lr, eps=1e-7, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    min_val_loss = 1e15\n",
    "    wait = 0\n",
    "    stopped_epoch = 0\n",
    "    stop_training = False\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (batch, labels) in enumerate(train_generator):\n",
    "            # Transfer to GPU\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            \n",
    "            batch_size = batch.shape[0]\n",
    "            \n",
    "            # Model\n",
    "            output = model(batch)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * batch_size\n",
    "            \n",
    "        train_loss = train_loss / (len(train_generator.dataset))\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for batch, labels in validation_data:\n",
    "                # Transfer to GPU\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                \n",
    "                batch_size = batch.shape[0]\n",
    "                \n",
    "                output = model(batch)\n",
    "\n",
    "                val_loss = val_loss + criterion(output, labels).item() * batch_size\n",
    "                \n",
    "        val_loss = val_loss / (len(validation_data.dataset))\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        # Print stuff\n",
    "        print('Epoch: {e:3d}/{n_e:3d}  - loss: {l:.3f}  - val_loss: {v_l:.5f}  - time: {t:2f}'\n",
    "              .format(e=epoch+1, n_e=epochs, l=train_loss, v_l=val_loss, t=time2-time1))\n",
    "                \n",
    "            \n",
    "        if (val_loss - min_val_loss) < 0:\n",
    "            min_val_loss = val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            if wait >= patience:\n",
    "                stopped_epoch = epoch + 1\n",
    "                stop_training = True\n",
    "            wait += 1\n",
    "        \n",
    "        if stop_training:\n",
    "            print('Epoch {e:3d}: early stopping'.format(e=stopped_epoch))\n",
    "            return train_losses, val_losses\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 day prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "Loading data into RAM\n"
     ]
    }
   ],
   "source": [
    "lead_time = 72\n",
    "model_save_fn = \"/mnt/scratch/students/illorens/data/predictions/models/torch_fccnn_3d.h5\"\n",
    "pred_save_fn = \"/mnt/scratch/students/illorens/data/predictions/torch_fccnn_3d.nc\"\n",
    "\n",
    "# 1. Open dataset and create data generators\n",
    "z = xr.open_mfdataset(f'{datadir}geopotential_500/*.nc', combine='by_coords')\n",
    "t = xr.open_mfdataset(f'{datadir}temperature_850/*.nc', combine='by_coords')\n",
    "ds = xr.merge([z, t], compat='override')  # Override level. discarded later anyway.\n",
    "\n",
    "lat = ds.dims['lat']\n",
    "lon = ds.dims['lon']\n",
    "nodes = lat * lon\n",
    "ratio = lon/lat\n",
    "\n",
    "ds_train = ds.sel(time=slice(*train_years))\n",
    "ds_valid = ds.sel(time=slice(*valid_years))\n",
    "ds_test = ds.sel(time=slice(*test_years))\n",
    "\n",
    "dic = {var: None for var in vars}\n",
    "\n",
    "dataset_train = Dataset_WeatherBench_1D(ds_train, dic, lead_time)\n",
    "dataset_valid = Dataset_WeatherBench_1D(ds_valid, dic, lead_time, mean=dataset_train.mean, std=dataset_train.std)\n",
    "dataset_test = Dataset_WeatherBench_1D(ds_test, dic, lead_time, mean=dataset_train.mean, std=dataset_train.std)\n",
    "\n",
    "dg_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "dg_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "dg_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 100\n",
    "patience = 3\n",
    "gpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spherical Graph CNN, WeatherBench architecture ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherical_cnn = SphericalCNN(N=nodes, ratio=ratio, in_channels=2, out_channels=2, kernel_size=5)\n",
    "spherical_cnn, device = init_device(spherical_cnn, gpu=[1])\n",
    "\n",
    "# Train model\n",
    "train_loss, val_loss = train_model(spherical_cnn, device, dg_train, epochs=epochs, lr=lr, \n",
    "                                   validation_data=dg_valid, patience=patience)\n",
    "\n",
    "print(f'Saving model weights: {model_save_fn}')\n",
    "torch.save(model.state_dict(), model_save_fn)\n",
    "\n",
    "# Create predictions\n",
    "pred = create_predictions(model, dg_test, lat, lon, mean=dataset_train.mean, std=dataset_train.std)\n",
    "print(f'Saving predictions: {pred_save_fn}')\n",
    "pred.to_netcdf(pred_save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = load_test_data(datadir, lead_time)\n",
    "compute_weighted_rmse(pred, valid).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_model(pred, valid, 'Spherical_CNN_weatherbench_architecture_3_days')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
